#load("../string.che")
#load("token.che")

struct Lexer {
    text: String
    location: TokenLocation
}

fn IsIdentBegin(c: byte) -> bool {    
    return (c >= 'a' and c <= 'z') or (c >= 'A' and c <= 'Z')
}

fn IsIdentChar(c: byte) -> bool {
    return IsIdentBegin(c) or (c >= '0' and c <= '9')
}

impl Lexer {
    ref fn Init(filename: string) -> bool {
        text = NewString()
        if LoadFile(filename, &text) == false { return false }

        location = new TokenLocation {
            filename, 1, 0, 0
        }

        return true
    }

    ref fn Cleanup() {
        text.Dispose()
    }

    ref fn NextToken() -> Token {
        let token = new Token {
            TokenType.Unknown
            location.Clone()
        }

        self.SkipNewlinesAndComments()

        if location.start >= text.length {
            token.type = TokenType.EOF
            return token
        }

        let c = self.PeekChar(0)

        
        match c {
            ':' -> MakeSimpleToken(&token, TokenType.Colon),
            ';' -> MakeSimpleToken(&token, TokenType.Semicolon),
            '.' -> MakeSimpleToken(&token, TokenType.Period),
            '=' -> MakeSimpleToken(&token, TokenType.Equal),
            '(' -> MakeSimpleToken(&token, TokenType.OpenParen),
            ')' -> MakeSimpleToken(&token, TokenType.ClosingParen),
            '{' -> MakeSimpleToken(&token, TokenType.OpenBrace),
            '}' -> MakeSimpleToken(&token, TokenType.ClosingBrace),
            '[' -> MakeSimpleToken(&token, TokenType.OpenBracket),
            ']' -> MakeSimpleToken(&token, TokenType.ClosingBracket),
            ',' -> MakeSimpleToken(&token, TokenType.Comma),
            '&' -> MakeSimpleToken(&token, TokenType.Ampersand),
            '*' -> MakeSimpleToken(&token, TokenType.Asterisk),
            '/' -> MakeSimpleToken(&token, TokenType.ForwardSlash),
            '+' -> MakeSimpleToken(&token, TokenType.Plus),
            '%' -> MakeSimpleToken(&token, TokenType.Percent),
            '-' -> MakeSimpleToken(&token, TokenType.Minus),
            '<' -> MakeSimpleToken(&token, TokenType.Less),
            '>' -> MakeSimpleToken(&token, TokenType.Greater),
            '^' -> MakeSimpleToken(&token, TokenType.Hat),
            '!' -> MakeSimpleToken(&token, TokenType.Bang),
        }

        if token.type = TokenType.Unknown {
            token.type = TokenType.Identifier
        }

        return token
    }

    ref fn MakeSimpleToken(token: Token&, type: TokenType) {
        location.start = location.start + 1

        token.type = type
        token.location.end = token.location.start + 1
    }

    ref fn PeekChar(offset: int) -> byte {
        let index = location.start + offset
        if index >= text.length {
            return 0
        }

        return text.data[index]
    }

    ref fn SkipNewlinesAndComments() {

    }
}
