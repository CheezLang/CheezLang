#load("std:preload")
#load("std:io/file")

#load("token")
#load("string_database")
#load("cheez_compiler")


struct Lexer {
    text        : String
    location    : TokenLocation
    peek        : Option(Token)
    compiler    : ref CheezCompiler
    string_db   : ref StringDatabase

    
    // interned keywords
    KwReturn    : string
    KwNew       : string
    KwRef       : string
    KwFn        : string
    KwStruct    : string
    KwEnum      : string
    KwImpl      : string
    KwConst     : string
    KwLet       : string
    KwTypedef   : string
    KwIf        : string
    KwElse      : string
    KwFor       : string
    KwWhile     : string
    KwAnd       : string
    KwOr        : string
    KwTrue      : string
    KwFalse     : string
    KwNull      : string
    KwUsing     : string
    KwDefer     : string
    KwMatch     : string
    KwBreak     : string
    KwContinue  : string
    KwTrait     : string
    KwCast      : string
}

fn is_ident_begin(c: char) -> bool {
    return (c >= 'a' and c <= 'z') or (c >= 'A' and c <= 'Z') or (c == '_')
}

fn is_ident_char(c: char) -> bool {
    return is_ident_begin(c) or (c >= '0' and c <= '9')
}

fn is_digit(c: char) -> bool {
    return c >= '0' and c <= '9'
}

fn is_hex_digit(c: char) -> bool {
    return (c >= '0' and c <= '9') or (c >= 'a' and c <= 'f') or (c >= 'A' and c <= 'F')
}

fn is_binary_digit(c: char) -> bool {
    return c >= '0' and c <= '1'
}

enum LexerNumberState {
    Error
    Init
    Z
    X
    B
    DecDigit
    BinDigit
    HexDigit
    Done
    FloatPoint
    FloatDigit
}

impl Lexer {
    fn from_file(filename: string, comp: ref CheezCompiler) -> Result(Lexer, String) {
        return match load_file(filename) {
            Ok($content) -> Ok(new Lexer {
                text = content
                location = new {
                    file = filename
                    line = 1
                }
                peek = None
                compiler = comp
                string_db = comp.string_database

                KwReturn    = comp.string_database.intern("return")
                KwNew       = comp.string_database.intern("new")
                KwRef       = comp.string_database.intern("ref")
                KwFn        = comp.string_database.intern("fn")
                KwStruct    = comp.string_database.intern("struct")
                KwEnum      = comp.string_database.intern("enum")
                KwImpl      = comp.string_database.intern("impl")
                KwConst     = comp.string_database.intern("const")
                KwLet       = comp.string_database.intern("let")
                KwTypedef   = comp.string_database.intern("typedef")
                KwIf        = comp.string_database.intern("if")
                KwElse      = comp.string_database.intern("else")
                KwFor       = comp.string_database.intern("for")
                KwWhile     = comp.string_database.intern("while")
                KwAnd       = comp.string_database.intern("and")
                KwOr        = comp.string_database.intern("or")
                KwTrue      = comp.string_database.intern("true")
                KwFalse     = comp.string_database.intern("false")
                KwNull      = comp.string_database.intern("null")
                KwUsing     = comp.string_database.intern("using")
                KwDefer     = comp.string_database.intern("defer")
                KwMatch     = comp.string_database.intern("match")
                KwBreak     = comp.string_database.intern("break")
                KwContinue  = comp.string_database.intern("continue")
                KwTrait     = comp.string_database.intern("trait")
                KwCast      = comp.string_database.intern("cast")
            })

            Err($msg) -> Err(msg)
        }
    }

    fn dispose(ref Self) {
        text.free()
    }

    fn peek_token(ref Self) -> Token {
        return match peek {
            Some($tok) -> tok

            None -> {
                let tok = next_token()
                peek = Some(tok)
                tok
            }
        }
    }

    fn next_token(ref Self) -> Token {
        match peek {
            Some($t) -> {
                peek = None
                return t
            }
        }

        match skip_newlines_and_comments() {
            Some($loc) -> {
                loc.end = loc.index
                return new Token {
                    ttype = TokenType.NewLine
                    location = loc
                    suffix = None
                    data = TokenData.None
                }
            }
        }

        return read_token()
    }

    fn read_token(ref Self) -> Token {
        let token = new Token {
            ttype = TokenType.EOF
            data = TokenData.None
            location = location
            suffix = None
        }
        token.location.end = token.location.index

        if location.index >= text.length {
            return token
        }

        let curr = peek_char(0)
        let next = peek_char(1)

        match curr {
            '=' if next == '=' -> simple_token(token, TokenType.DoubleEqual, 2)
            '!' if next == '=' -> simple_token(token, TokenType.NotEqual, 2)
            '<' if next == '=' -> simple_token(token, TokenType.LessEqual, 2)
            '<' if next == '<' -> simple_token(token, TokenType.LessLess, 2)
            '>' if next == '=' -> simple_token(token, TokenType.GreaterEqual, 2)
            ':' if next == ':' -> simple_token(token, TokenType.DoubleColon, 2)
            '-' if next == '>' -> simple_token(token, TokenType.Arrow, 2)
            '+' if next == '=' -> simple_token(token, TokenType.AddEq, 2)
            '-' if next == '=' -> simple_token(token, TokenType.SubEq, 2)
            '*' if next == '=' -> simple_token(token, TokenType.MulEq, 2)
            '/' if next == '=' -> simple_token(token, TokenType.DivEq, 2)
            '%' if next == '=' -> simple_token(token, TokenType.ModEq, 2)
            ':' -> simple_token(token, TokenType.Colon)
            ';' -> simple_token(token, TokenType.Semicolon)
            '.' -> simple_token(token, TokenType.Period)
            '=' -> simple_token(token, TokenType.Equal)
            '(' -> simple_token(token, TokenType.OpenParen)
            ')' -> simple_token(token, TokenType.ClosingParen)
            '{' -> simple_token(token, TokenType.OpenBrace)
            '}' -> simple_token(token, TokenType.ClosingBrace)
            '[' -> simple_token(token, TokenType.OpenBracket)
            ']' -> simple_token(token, TokenType.ClosingBracket)
            ',' -> simple_token(token, TokenType.Comma)
            '&' -> simple_token(token, TokenType.Ampersand)
            '*' -> simple_token(token, TokenType.Asterisk)
            '/' -> simple_token(token, TokenType.ForwardSlash)
            '+' -> simple_token(token, TokenType.Plus)
            '%' -> simple_token(token, TokenType.Percent)
            '-' -> simple_token(token, TokenType.Minus)
            '<' -> simple_token(token, TokenType.Less)
            '>' -> simple_token(token, TokenType.Greater)
            '!' -> simple_token(token, TokenType.Bang)

            '"' -> {
                parse_string_literal(token, TokenType.StringLiteral, '"')
                parse_suffix(token)
            }
            '`'' -> {
                parse_string_literal(token, TokenType.CharLiteral, '`'')
                parse_suffix(token)
            }

            // identifiers and keywords
            '$' -> {
                location.index += 1
                parse_identifier(token, TokenType.DollarIdentifier)
            }
            '#' ->  {
                location.index += 1
                parse_identifier(token, TokenType.HashIdentifier)
            }
            '@' ->  {
                location.index += 1
                parse_identifier(token, TokenType.AtSignIdentifier)
            }
            $x if is_ident_begin(x) -> {
                parse_identifier(token, TokenType.Identifier)
                check_keywords(token)
                // check_keywords_raw(token)
            }

            // number literal
            $x if is_digit(x) -> {
                parse_number_literal(token)
                parse_suffix(token)
            }

            $_ -> {
                token.ttype = TokenType.Unknown
                location.index += 1
            }
        }

        token.location.end = location.index

        return token
    }

    fn parse_number_literal(ref Self, token: ref Token) {
        token.ttype = TokenType.NumberLiteral
        let base = 10
        let str = {
            let const cap = 64
            let raw = @alloca(char, cap)
            let str = String::from_raw_ptr(raw, cap)
            str
        }

        let isFloat = false

        use LexerNumberState

        let state = Init
        while location.index < text.length {
            let c = peek_char(0)
            match state {
                Error -> {break}
                Done  -> {break}

                Init  -> {
                    if c == '0' {
                        str += c
                        state = Z
                    } else if is_digit(c) {
                        str += c
                        state = DecDigit
                    }
                }

                Z -> match c {
                    'x' -> {
                        base = 16
                        str.length = 0
                        state = X
                    }
                    'b' -> {
                        base = 2
                        str.length = 0
                        state = B
                    }
                    '.' -> {
                        str += c
                        state = FloatPoint
                    }
                    $x if is_digit(x) -> {
                        str += x
                        state = DecDigit
                    }
                    $_ -> {
                        state = Done
                    }
                }

                DecDigit -> match c {
                    '.' -> {
                        str += c
                        state = FloatPoint
                    }
                    $x if is_digit(x) -> {
                        str += c
                    }
                    $_ -> {
                        state = Done
                    }
                }

                FloatPoint -> {
                    isFloat = true
                    if is_digit(c) {
                        str += c
                        state = FloatDigit
                    } else {
                        state = Error
                    }
                }

                FloatDigit -> match c {
                    $c if is_digit(c) -> {
                        str += c
                    }
                    $_ -> {
                        state = Done
                    }
                }

                X -> match c {
                    $c if is_hex_digit(c) -> {
                        str += c
                        state = HexDigit
                    }
                    $_ -> {
                        state = Error
                    }
                }

                HexDigit -> match c {
                    $c if is_hex_digit(c) -> {
                        str += c
                    }
                    $_ -> {
                        state = Done
                    }
                }

                B -> match c {
                    $c if is_binary_digit(c) -> {
                        str += c
                        state = BinDigit
                    }
                    $_ -> {
                        state = Error
                    }
                }

                BinDigit -> match c {
                    $c if is_binary_digit(c) -> {
                        str += c
                    }
                    $_ -> {
                        state = Done
                    }
                }
            }

            match state {
                Done -> {}
                $_   -> {
                    location.index += 1
                }
            }
        }

        match state {
            Error -> {
                // TODO: report error
                token.ttype = TokenType.Unknown
                return
            }
        }

        str += '`0'

        if isFloat {
            let d = c_strtod(str.get_raw(), null)
            token.data = TokenData.Double(d)
        } else {
            let i = c_strtol(str.get_raw(), null, cast base)
            token.data = TokenData.Integer(i)
        }
    }

    fn parse_suffix(ref Self, token: ref Token) {
        if is_ident_begin(peek_char(0)) {
            let start = location.index
            while location.index < text.length and is_ident_char(peek_char(0)) {
                location.index += 1
            }

            token.suffix = Some(text.sliceFL(start, location.index - start))
        }
    }

    fn simple_token(ref Self, token: ref Token, ttype: TokenType, len: int = 1) {
        token.ttype = ttype
        location.index += len
    }

    fn parse_identifier(ref Self, token: ref Token, ttype: TokenType) {
        token.ttype = ttype
        let start = location.index

        while location.index < text.length and is_ident_char(peek_char(0)) {
            location.index += 1
        }

        let str = text.sliceFL(start, location.index - start)
        token.data = TokenData.String(string_db.intern(str))
    }

    fn parse_string_literal(ref Self, token: ref Token, ttype: TokenType, end: char) {
        token.ttype = ttype
        location.index += 1
        let start = location.index

        let foundEnd = false
        while location.index < text.length {
            let c = peek_char(0)
            location.index += 1

            if c == end {
                foundEnd = true
                break
            }
            else if c == '``' {
                if location.index >= text.length {
                    // TODO: report error
                    break
                }

                location.index += 1
            }

            if c == '`n' {
                location.line += 1
                location.line_start = location.index
            }
        }

        if !foundEnd {
            // TODO: report
        }

        let str = text.sliceFL(start, location.index - start - 1)
        token.data = TokenData.String(string_db.intern(str))
    }

    fn skip_newlines_and_comments(ref Self) -> loc: Option(TokenLocation) {
        loc = None

        while location.index < text.length {
            let c = peek_char(0)
            let next = peek_char(1)

            if c == '/' and next == '*' {
                parse_multi_line_comment()
            }

            else if c == '/' and next == '/' {
                parse_single_line_comment()
            }

            else if c == ' ' or c == '`t' {
                location.index += 1
            }

            else if c == '`r' {
                location.index += 1
            }

            else if c == '`n' {
                match loc {
                    None -> {
                        loc = Some(location)
                    }
                }

                location.line += 1
                location.index += 1
                location.line_start = location.index
            }

            else {
                break
            }
        }
    }

    fn peek_char(ref Self, offset: int) -> char {
        let index = location.index + offset
        if index >= text.length {
            return '`0'
        }

        return text.data[index]
    }

    fn parse_multi_line_comment(ref Self) {
        let level = 0
        while location.index < text.length; location.index += 1 {
            let curr = peek_char(0)
            let next = peek_char(1)

            if curr == '/' and next == '*' {
                location.index += 1
                level += 1
            } else if curr == '*' and next == '/' {
                location.index += 1
                level -= 1

                if level == 0 {
                    break
                }
            } else if curr == '\n' {
                location.line += 1
                location.line_start = location.index
            }
        }
    }

    fn parse_single_line_comment(ref Self) {
        while location.index < text.length {
            if peek_char(0) == '`n' {
                break
            }

            location.index += 1
        }
    }

    fn check_keywords(ref Self, token: ref Token) {
        match token.data {
            TokenData.String($str) -> {
                if      str == KwReturn     { token.ttype = TokenType.KwReturn }
                else if str == KwNew        { token.ttype = TokenType.KwNew }
                else if str == KwRef        { token.ttype = TokenType.KwRef }
                else if str == KwFn         { token.ttype = TokenType.KwFn }
                else if str == KwStruct     { token.ttype = TokenType.KwStruct }
                else if str == KwEnum       { token.ttype = TokenType.KwEnum }
                else if str == KwImpl       { token.ttype = TokenType.KwImpl }
                else if str == KwConst      { token.ttype = TokenType.KwConst }
                else if str == KwLet        { token.ttype = TokenType.KwLet }
                else if str == KwTypedef    { token.ttype = TokenType.KwTypedef }
                else if str == KwIf         { token.ttype = TokenType.KwIf }
                else if str == KwElse       { token.ttype = TokenType.KwElse }
                else if str == KwFor        { token.ttype = TokenType.KwFor }
                else if str == KwWhile      { token.ttype = TokenType.KwWhile }
                else if str == KwAnd        { token.ttype = TokenType.KwAnd }
                else if str == KwOr         { token.ttype = TokenType.KwOr }
                else if str == KwTrue       { token.ttype = TokenType.KwTrue }
                else if str == KwFalse      { token.ttype = TokenType.KwFalse }
                else if str == KwNull       { token.ttype = TokenType.KwNull }
                else if str == KwUsing      { token.ttype = TokenType.KwUsing }
                else if str == KwDefer      { token.ttype = TokenType.KwDefer }
                else if str == KwMatch      { token.ttype = TokenType.KwMatch }
                else if str == KwBreak      { token.ttype = TokenType.KwBreak }
                else if str == KwContinue   { token.ttype = TokenType.KwContinue }
                else if str == KwTrait      { token.ttype = TokenType.KwTrait }
                else if str == KwCast       { token.ttype = TokenType.KwCast }
            }
        }
    }
}
