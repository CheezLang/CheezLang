use import std.array
use import std.string
use import std.unicode
util:: import std.util
mem :: import std.mem.allocator
fmt :: import std.fmt
io  :: import std.io

use import compiler.lexer
use import compiler.error_handler
use import compiler.string_database

#export_scope 

Parser :: trait(T: type) {
    parse :: (lexer: ref Lexer, error_handler: ErrorHandler) -> Option[T];
}


ParserHelper :: struct {}
impl ParserHelper {
    parse :: ($T: type, lexer: ref Lexer, error_handler: ErrorHandler) -> Option[T] {
        if const @type_has_trait(T, Parser[T]) {
            return T.parse(lexer, error_handler)
        } else if const @is_struct(T) {
            return parse_struct(T, lexer, error_handler)
        } else {
            return None
        }
    }

    parse_struct :: ($T: type, lexer: ref Lexer, error_handler: ErrorHandler) -> Option[T] {
        result := mem.alloc(T)
        defer mem.free(result)

        lexer.skip_newlines_and_comments()
        name := lexer.next_token()

        match name.ttype {
            TokenType.Identifier -> {
                if !streq(name.data.String, @typename(T)) {
                    error_handler.report_errorf(name.location, "Expected identifier '{}', got '{}'", [@typename(T), name.data.String])
                    return None
                }
            }

            _ -> {
                msg := "Expected identifier, got {}"
                error_handler.report_errorf(name.location, "Expected identifier, got {}", [name.ttype])
                return None
            }
        }

        eat_token(TokenType.OpenBrace)

        // parse members in a loop
        loop {
            lexer.skip_newlines_and_comments()

            token := lexer.peek_token()
            match token.ttype {
                TokenType.ClosingBrace -> break
                TokenType.EOF -> break
            }

            name_token := eat_token(TokenType.Identifier)

            eat_token(TokenType.Equal)

            @for_struct_members(T, (name, typ, offset) => {
                // io.printfln("{}: {} @{}", (name, @typename(typ), offset))
                if streq(name_token.data.String, name) {
                    member_ptr := cast(&typ) util.pointer_add(result, offset)

                    match ParserHelper.parse(typ, lexer, error_handler) {
                        Some($v) -> {
                            <<member_ptr = v
                            continue
                        }
                        None -> {
                            return None
                        }
                    }
                }
            })
            
            // temp
            error_handler.report_errorf(name_token.location, "Unexpected name. '{}' is not a member of struct {}", [name_token.data.String, @typename(T)])
            lexer.next_token()
        }

        eat_token(TokenType.ClosingBrace)
        lexer.skip_newlines_and_comments()
        return Some(<<result)
    }
}

// integer types
impl Parser[i8] for i8 {
    parse :: (lexer: ref Lexer, error_handler: ErrorHandler) -> Option[Self] {
        return parse_data_int(Self, lexer, error_handler)
    }
}

impl Parser[i16] for i16 {
    parse :: (lexer: ref Lexer, error_handler: ErrorHandler) -> Option[Self] {
        return parse_data_int(Self, lexer, error_handler)
    }
}

impl Parser[i32] for i32 {
    parse :: (lexer: ref Lexer, error_handler: ErrorHandler) -> Option[Self] {
        return parse_data_int(Self, lexer, error_handler)
    }
}

impl Parser[i64] for i64 {
    parse :: (lexer: ref Lexer, error_handler: ErrorHandler) -> Option[Self] {
        return parse_data_int(Self, lexer, error_handler)
    }
}

// unsigned
impl Parser[u8] for u8 {
    parse :: (lexer: ref Lexer, error_handler: ErrorHandler) -> Option[Self] {
        return parse_data_int(Self, lexer, error_handler)
    }
}

impl Parser[u16] for u16 {
    parse :: (lexer: ref Lexer, error_handler: ErrorHandler) -> Option[Self] {
        return parse_data_int(Self, lexer, error_handler)
    }
}

impl Parser[u32] for u32 {
    parse :: (lexer: ref Lexer, error_handler: ErrorHandler) -> Option[Self] {
        return parse_data_int(Self, lexer, error_handler)
    }
}

impl Parser[u64] for u64 {
    parse :: (lexer: ref Lexer, error_handler: ErrorHandler) -> Option[Self] {
        return parse_data_int(Self, lexer, error_handler)
    }
}

// char types
impl Parser[char8] for char8 {
    parse :: (lexer: ref Lexer, error_handler: ErrorHandler) -> Option[Self] {
        return parse_data_char(Self, lexer, error_handler)
    }
}

impl Parser[char16] for char16 {
    parse :: (lexer: ref Lexer, error_handler: ErrorHandler) -> Option[Self] {
        return parse_data_char(Self, lexer, error_handler)
    }
}

impl Parser[char32] for char32 {
    parse :: (lexer: ref Lexer, error_handler: ErrorHandler) -> Option[Self] {
        return parse_data_char(Self, lexer, error_handler)
    }
}

// float types
impl Parser[f32] for f32 {
    parse :: (lexer: ref Lexer, error_handler: ErrorHandler) -> Option[Self] {
        return parse_data_float(Self, lexer, error_handler)
    }
}

impl Parser[f64] for f64 {
    parse :: (lexer: ref Lexer, error_handler: ErrorHandler) -> Option[Self] {
        return parse_data_float(Self, lexer, error_handler)
    }
}

// bool
impl Parser[bool] for bool {
    parse :: (lexer: ref Lexer, error_handler: ErrorHandler) -> Option[Self] {
        lexer.skip_newlines_and_comments()
        token := lexer.next_token()
        return match token.ttype {
            TokenType.KwTrue -> Some(true)
            TokenType.KwFalse -> Some(false)
            _ -> {
                msg := fmt.format("Unexpected token {}, expected true/false", [token.ttype])
                error_handler.report_error(token.location, msg.slice())
                None
            }
        }
    }
}

// strings
impl Parser[string] for string {
    parse :: (lexer: ref Lexer, error_handler: ErrorHandler) -> Option[Self] {
        return parse_data_string(Self, lexer, error_handler)
    }
}

impl Parser[String] for String {
    parse :: (lexer: ref Lexer, error_handler: ErrorHandler) -> Option[Self] {
        return parse_data_string(Self, lexer, error_handler)
    }
}

// array
impl(T: type) Parser[Array[T]] for Array[T] if T : Parser[T] {
    parse :: (lexer: ref Lexer, error_handler: ErrorHandler) -> Option[Array[T]] {
        result := Array[T].create()

        lexer.skip_newlines_and_comments()

        // [
        open_bracket := lexer.next_token()
        if int(open_bracket.ttype) != int(TokenType.OpenBracket) {
            error_handler.report_error(open_bracket.location, "Expected opening bracket")
            return None
        }
        
        loop {
            lexer.skip_newlines_and_comments()
            token := lexer.peek_token()

            match token.ttype {
                TokenType.EOF -> break
                TokenType.ClosingBracket -> break
            }

            match T.parse(lexer, error_handler) {
                Some($d) -> result.add(d)
                None -> {return None}
            }

            // expect comma, new_line, ] or EOF
            token = lexer.peek_token()
            match token.ttype {
                TokenType.Comma          -> lexer.next_token()
                TokenType.NewLine        -> lexer.next_token()
                TokenType.EOF            -> break
                TokenType.ClosingBracket -> break
            }
        }

        // ]
        closing_bracket := lexer.next_token()
        if int(closing_bracket.ttype) != int(TokenType.ClosingBracket) {
            error_handler.report_error(closing_bracket.location, "Expected closing bracket")
            return None
        }

        return Some(result)
    }
}

#file_scope
parse_data_float :: ($T: type, lexer: ref Lexer, error_handler: ErrorHandler) -> Option[T] {
    lexer.skip_newlines_and_comments()
    token := lexer.next_token()
    return match token.ttype {
        TokenType.NumberLiteral -> {
            match token.data {
                TokenData.Integer($v) -> Some(T(v))
                TokenData.Double($v)  -> Some(T(v))
                _ -> {
                    msg := fmt.format("Can't parse non-number literal into an {}", [@typename(T)])
                    error_handler.report_error(token.location, msg.slice())
                    None
                }
            }
        }
        _ -> {
            msg := fmt.format("Unexpected token {}, expected number literal", [token.ttype])
            error_handler.report_error(token.location, msg.slice())
            None
        }
    }
}

parse_data_char :: ($T: type, lexer: ref Lexer, error_handler: ErrorHandler) -> Option[T] {
    lexer.skip_newlines_and_comments()
    token := lexer.next_token()
    return match token.ttype {
        TokenType.CharLiteral -> {
            match token.data {
                TokenData.String($v) -> {
                    ch, len := Utf8.decode(v.bytes)
                    Some(T(ch))
                }
                _ -> {
                    msg := fmt.format("Can't parse non-char literal into {}", [@typename(T)])
                    error_handler.report_error(token.location, msg.slice())
                    None
                }
            }
        }
        _ -> {
            msg := fmt.format("Unexpected token {}, expected integer char", [token.ttype])
            error_handler.report_error(token.location, msg.slice())
            None
        }
    }
}

parse_data_int :: ($T: type, lexer: ref Lexer, error_handler: ErrorHandler) -> Option[T] {
    lexer.skip_newlines_and_comments()
    token := lexer.next_token()
    return match token.ttype {
        TokenType.NumberLiteral -> {
            match token.data {
                TokenData.Integer($v) -> Some(T(v))
                _ -> {
                    msg := fmt.format("Can't parse non-integer literal into an {}", [@typename(T)])
                    error_handler.report_error(token.location, msg.slice())
                    None
                }
            }
        }
        _ -> {
            msg := fmt.format("Unexpected token {}, expected integer literal", [token.ttype])
            error_handler.report_error(token.location, msg.slice())
            None
        }
    }
}

parse_data_string :: ($T: type, lexer: ref Lexer, error_handler: ErrorHandler) -> Option[T] {
    lexer.skip_newlines_and_comments()
    token := lexer.next_token()
    return match token.ttype {
        TokenType.StringLiteral -> {
            match token.data {
                TokenData.String($v) -> {
                    match T {
                        string -> Some(v)
                        String -> Some(String.from_string(v))
                        _ -> @static_assert(false, "That shouldn't happen... " + @typename(T))
                    }
                }
                _ -> {
                    msg := fmt.format("Can't parse non-string literal into {}", [@typename(T)])
                    error_handler.report_error(token.location, msg.slice())
                    None
                }
            }
        }
        _ -> {
            msg := fmt.format("Unexpected token {}, expected string literal", [token.ttype])
            error_handler.report_error(token.location, msg.slice())
            None
        }
    }
}

#file_scope

eat_token :: (typ: TokenType) #macro {
    if (ok, t) := @link(lexer).expect_token(typ), ok {
        t
    } else {
        @link(error_handler).report_errorf(t.location, "Expected '{}', got {}", [typ, t.ttype])
        return None
    }
}
