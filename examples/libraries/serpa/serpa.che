use import std.array
use import std.string
use import std.unicode
use import std.rc
util:: import std.util
mem :: import std.mem.allocator
fmt :: import std.fmt
io  :: import std.io

use import compiler.lexer
use import compiler.error_handler
use import compiler.string_database

#export_scope

IParser :: trait(T: type) {
    parse :: (parser: &Parser, lexer: &Lexer, error_handler: ^ErrorHandler) -> Option[T];
}

Parser :: struct {
    expect_struct_name := true
}

impl Parser {
    parse :: (&Self, $T: type, lexer: &Lexer, error_handler: ^ErrorHandler) -> Option[T] {
        if const @type_has_trait(T, IParser[T]) {
            return T.parse(self, lexer, error_handler)
        } else if const @is_struct(T) {
            return self.parse_struct(T, lexer, error_handler)
        } else {
            return None
        }
    }

    parse_struct_into :: (&Self, result: ^$T, lexer: &Lexer, error_handler: ^ErrorHandler) -> bool {
        eat_token :: (typ: TokenType) #macro {
            if (ok, t) := @link(lexer).expect_token(typ), ok {
                t
            } else {
                @link(error_handler).report_error_at(t.location, "Expected '{}', got {}", [typ, t.typ])
                return false
            }
        }

        lexer.skip_newlines_and_comments()

        if expect_struct_name {
            name_token := lexer.next_token()

            match name_token.typ {
                TokenType.Identifier -> {
                    if !streq(name_token.data.String, @typename(T)) {
                        error_handler.report_error_at(name_token.location, "Expected identifier '{}', got '{}'", [@typename(T), name_token.data.String])
                        return false
                    }
                }

                _ -> {
                    msg := "Expected identifier, got {}"
                    error_handler.report_error_at(name_token.location, "Expected identifier, got {}", [name_token.typ])
                    return false
                }
            }
        }

        eat_token(TokenType.OpenBrace)

        // parse members in a loop
        loop {
            lexer.skip_newlines_and_comments()

            token := lexer.peek_token()
            match token.typ {
                TokenType.ClosingBrace -> break
                TokenType.EOF -> break
            }

            name_token := eat_token(TokenType.Identifier)
            eat_token(TokenType.Equal)

            found_member := false
            @for_struct_members(T, (name, typ, offset) => {
                // io.printfln("{}: {} @{}  ?= {}", (name, @typename(typ), offset, name_token.data.String))
                if streq(name_token.data.String, name) {
                    member_ptr := cast(^typ) util.pointer_add(result, offset)

                    match self.parse(typ, lexer, error_handler) {
                        Some($v) -> {
                            *member_ptr = v
                            found_member = true
                        }
                        None -> {
                            return false
                        }
                    }
                }
            })

            if found_member {
                token := lexer.peek_token()
                match token.typ {
                    TokenType.Comma -> lexer.next_token()
                    TokenType.NewLine -> lexer.next_token()
                    TokenType.ClosingBrace -> break
                    TokenType.EOF -> break
                    _ -> {
                        error_handler.report_error_at(token.location, "Expected ',' | '\n' | '}' | EOF. Got '{}'", [token.typ])
                        lexer.next_token()
                        return false
                    }
                }
            } else {
                error_handler.report_error_at(name_token.location, "Unexpected name. '{}' is not a member of struct {}", [name_token.data.String, @typename(T)])
                lexer.next_token()
                return false
            }
        }

        eat_token(TokenType.ClosingBrace)

        return true
    }

    parse_struct :: (&Self, $T: type, lexer: &Lexer, error_handler: ^ErrorHandler) -> Option[T] {
        result := mem.alloc(T)
        defer mem.free(result)
        if !parse_struct_into(result, lexer, error_handler) {
            return None
        }
        return Some(*result)
    }
}

// integer types
impl IParser[i8] for i8 {
    parse :: (parser: &Parser, lexer: &Lexer, error_handler: ^ErrorHandler) -> Option[Self] {
        return parse_data_int(Self, lexer, error_handler)
    }
}

impl IParser[i16] for i16 {
    parse :: (parser: &Parser, lexer: &Lexer, error_handler: ^ErrorHandler) -> Option[Self] {
        return parse_data_int(Self, lexer, error_handler)
    }
}

impl IParser[i32] for i32 {
    parse :: (parser: &Parser, lexer: &Lexer, error_handler: ^ErrorHandler) -> Option[Self] {
        return parse_data_int(Self, lexer, error_handler)
    }
}

impl IParser[i64] for i64 {
    parse :: (parser: &Parser, lexer: &Lexer, error_handler: ^ErrorHandler) -> Option[Self] {
        return parse_data_int(Self, lexer, error_handler)
    }
}

// unsigned
impl IParser[u8] for u8 {
    parse :: (parser: &Parser, lexer: &Lexer, error_handler: ^ErrorHandler) -> Option[Self] {
        return parse_data_int(Self, lexer, error_handler)
    }
}

impl IParser[u16] for u16 {
    parse :: (parser: &Parser, lexer: &Lexer, error_handler: ^ErrorHandler) -> Option[Self] {
        return parse_data_int(Self, lexer, error_handler)
    }
}

impl IParser[u32] for u32 {
    parse :: (parser: &Parser, lexer: &Lexer, error_handler: ^ErrorHandler) -> Option[Self] {
        return parse_data_int(Self, lexer, error_handler)
    }
}

impl IParser[u64] for u64 {
    parse :: (parser: &Parser, lexer: &Lexer, error_handler: ^ErrorHandler) -> Option[Self] {
        return parse_data_int(Self, lexer, error_handler)
    }
}

// char types
impl IParser[char8] for char8 {
    parse :: (parser: &Parser, lexer: &Lexer, error_handler: ^ErrorHandler) -> Option[Self] {
        return parse_data_char(Self, lexer, error_handler)
    }
}

impl IParser[char16] for char16 {
    parse :: (parser: &Parser, lexer: &Lexer, error_handler: ^ErrorHandler) -> Option[Self] {
        return parse_data_char(Self, lexer, error_handler)
    }
}

impl IParser[char32] for char32 {
    parse :: (parser: &Parser, lexer: &Lexer, error_handler: ^ErrorHandler) -> Option[Self] {
        return parse_data_char(Self, lexer, error_handler)
    }
}

// float types
impl IParser[f32] for f32 {
    parse :: (parser: &Parser, lexer: &Lexer, error_handler: ^ErrorHandler) -> Option[Self] {
        return parse_data_float(Self, lexer, error_handler)
    }
}

impl IParser[f64] for f64 {
    parse :: (parser: &Parser, lexer: &Lexer, error_handler: ^ErrorHandler) -> Option[Self] {
        return parse_data_float(Self, lexer, error_handler)
    }
}

// bool
impl IParser[bool] for bool {
    parse :: (parser: &Parser, lexer: &Lexer, error_handler: ^ErrorHandler) -> Option[Self] {
        lexer.skip_newlines_and_comments()
        token := lexer.next_token()
        return match token.typ {
            TokenType.KwTrue -> Some(true)
            TokenType.KwFalse -> Some(false)
            _ -> {
                error_handler.report_error_at(token.location, "Unexpected token {}, expected true/false", [token.typ])
                None
            }
        }
    }
}

// strings
impl IParser[string] for string {
    parse :: (parser: &Parser, lexer: &Lexer, error_handler: ^ErrorHandler) -> Option[Self] {
        return parse_data_string(Self, lexer, error_handler)
    }
}

impl IParser[String] for String {
    parse :: (parser: &Parser, lexer: &Lexer, error_handler: ^ErrorHandler) -> Option[Self] {
        return parse_data_string(Self, lexer, error_handler)
    }
}

// rc
// impl(T: type) IParser[Rc[T]] for Rc[T] if T : IParser[T] {
//     parse :: (parser: &Parser, lexer: &Lexer, error_handler: ^ErrorHandler) -> Option[Self] {
//         return match parser.parse(T, lexer, error_handler) {
//             Some($i) -> Some(Rc[T].new(i))
//             None -> None
//         }
//     }
// }

// array
impl(T: type) IParser[Array[T]] for Array[T] {
    parse :: (parser: &Parser, lexer: &Lexer, error_handler: ^ErrorHandler) -> Option[Array[T]] {
        result := Array[T].create()

        lexer.skip_newlines_and_comments()

        // [
        open_bracket := lexer.next_token()
        if int(open_bracket.typ) != int(TokenType.OpenBracket) {
            error_handler.report_error_at(open_bracket.location, "Expected opening bracket")
            return None
        }
        
        loop {
            lexer.skip_newlines_and_comments()
            token := *lexer.peek_token()

            match token.typ {
                TokenType.EOF -> break
                TokenType.ClosingBracket -> break
            }

            match parser.parse(T, lexer, error_handler) {
                Some($d) -> result.add(d)
                None -> {return None}
            }

            // expect comma, new_line, ] or EOF
            token = *lexer.peek_token()
            match token.typ {
                TokenType.Comma          -> lexer.next_token()
                TokenType.NewLine        -> lexer.next_token()
                TokenType.EOF            -> break
                TokenType.ClosingBracket -> break
            }
        }

        // ]
        closing_bracket := lexer.next_token()
        if int(closing_bracket.typ) != int(TokenType.ClosingBracket) {
            error_handler.report_error_at(closing_bracket.location, "Expected closing bracket")
            return None
        }

        return Some(result)
    }
}

#file_scope
parse_data_float :: ($T: type, lexer: &Lexer, error_handler: ^ErrorHandler) -> Option[T] {
    lexer.skip_newlines_and_comments()
    token := lexer.next_token()

    sign : T = 1
    if token.typ == TokenType.Minus {
        sign = -1
        token = lexer.next_token()
    }

    return match token.typ {
        TokenType.NumberLiteral -> {
            match token.data {
                TokenData.Integer($v) -> Some(T(v) * sign)
                TokenData.Double($v)  -> Some(T(v) * sign)
                _ -> {
                    msg := fmt.format("Can't parse non-number literal into an {}", [@typename(T)])
                    error_handler.report_error_at(token.location, msg.slice())
                    None
                }
            }
        }
        _ -> {
            msg := fmt.format("Unexpected token {}, expected number literal", [token.typ])
            error_handler.report_error_at(token.location, msg.slice())
            None
        }
    }
}

parse_data_char :: ($T: type, lexer: &Lexer, error_handler: ^ErrorHandler) -> Option[T] {
    lexer.skip_newlines_and_comments()
    token := lexer.next_token()
    return match token.typ {
        TokenType.CharLiteral -> {
            match token.data {
                TokenData.String($v) -> {
                    ch, len := Utf8.decode(v.bytes)
                    Some(T(ch))
                }
                _ -> {
                    msg := fmt.format("Can't parse non-char literal into {}", [@typename(T)])
                    error_handler.report_error_at(token.location, msg.slice())
                    None
                }
            }
        }
        _ -> {
            msg := fmt.format("Unexpected token {}, expected integer char", [token.typ])
            error_handler.report_error_at(token.location, msg.slice())
            None
        }
    }
}

parse_data_int :: ($T: type, lexer: &Lexer, error_handler: ^ErrorHandler) -> Option[T] {
    lexer.skip_newlines_and_comments()
    token := lexer.next_token()

    sign : T = 1
    if token.typ == TokenType.Minus {
        sign = -1
        token = lexer.next_token()
    }

    return match token.typ {
        TokenType.NumberLiteral -> {
            match token.data {
                TokenData.Integer($v) -> Some(T(v) * sign)
                _ -> {
                    msg := fmt.format("Can't parse non-integer literal into an {}", [@typename(T)])
                    error_handler.report_error_at(token.location, msg.slice())
                    None
                }
            }
        }
        _ -> {
            msg := fmt.format("Unexpected token {}, expected integer literal", [token.typ])
            error_handler.report_error_at(token.location, msg.slice())
            None
        }
    }
}

parse_data_string :: ($T: type, lexer: &Lexer, error_handler: ^ErrorHandler) -> Option[T] {
    lexer.skip_newlines_and_comments()
    token := lexer.next_token()
    return match token.typ {
        TokenType.StringLiteral -> {
            match token.data {
                TokenData.String($v) -> {
                    match T {
                        string -> Some(v)
                        String -> Some(String.from_string(v))
                        _ -> @static_assert(false, "That shouldn't happen... " + @typename(T))
                    }
                }
                _ -> {
                    msg := fmt.format("Can't parse non-string literal into {}", [@typename(T)])
                    error_handler.report_error_at(token.location, msg.slice())
                    None
                }
            }
        }
        _ -> {
            msg := fmt.format("Unexpected token {}, expected string literal", [token.typ])
            error_handler.report_error_at(token.location, msg.slice())
            None
        }
    }
}

eat_token :: (typ: TokenType) #macro {
    if (ok, t) := @link(lexer).expect_token(typ), ok {
        t
    } else {
        @link(error_handler).report_error_at(t.location, "Expected '{}', got {}", [typ, t.typ])
        return None
    }
}
