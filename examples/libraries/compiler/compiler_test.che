use import std.array
use import std.ring_queue
use import std.fiber
use import std.thread
use import std.time
use import std.os.windows_functions
use import std.os.windows_types
use import std.os.windows_constants
use import std.rc
use import std.string
use import std.mem.std_heap_allocator

mem :: import std.mem.allocator
C   :: import std.c
io  :: import std.io

use import compiler.interpreter
use import compiler.bytecode_generator
use import compiler.string_database
use import compiler.error_handler
use import compiler.ast
use import compiler.lexer
use import compiler.parser
use import compiler.ast_dumper
use import logging.logger


enable_profiler :: false

Main :: () {
    // Fiber.init()

    console_error_handler := ConsoleErrorHandler.new(null)

    compiler := Compiler.new(1, &console_error_handler)

    compiler.get().add_job(LoadFileJob(path = "P:/dev/CheezLang/data/basic_cheez.che".to_owned()))

    start := get_time_milliseconds()
    compiler.get().start_compilation()
    compiler.get().wait_until_done()
    end := get_time_milliseconds()
    dur := end - start
    io.printfln("Compilation took {} ms", dur)
}

CompilationJob :: trait {
    progressed  : bool = false
    done        : bool = false
}

impl CompileGlobalNodeJob {
    wait_for_bytecode :: (ref Self, wait_for: &AstFunction) {
        // id := job.id

        fiber_context := cast(&FiberContext) Fiber.current().user_data
        self.progressed = true

        while yield_count := 0, true, yield_count += 1 {
            if wait_for != null and wait_for.bytecode == null {
                if yield_count > 0 {
                    self.progressed = false
                }

                io.formatln("[{}] [Job] suspending #{} waiting for #{}", [fiber_context.thread, node.id, wait_for.id])
                Fiber.yield()
                io.formatln("[{}] [Job] resuming #{} waiting for #{}", [fiber_context.thread, node.id, wait_for.id])
            } else {
                io.formatln("[{}] [Job] done #{} waiting for #{}", [fiber_context.thread, node.id, wait_for.id])
                break
            }
        }
        self.progressed = true
    }
}

CompileGlobalNodeJob :: struct CompilationJob {
    node : &AstNode
}

LoadFileJob :: struct CompilationJob {
    path : String
}

FiberContext :: struct {
    fiber   : &Fiber
    job     : &CompilationJob = null
    thread  : int = -1
}

Compiler :: struct {
    jobs            := RingQueue[&CompilationJob].new()

    fibers          := Array[&FiberContext].create(1024)
    waiting_fibers  := RingQueue[&FiberContext].new()
    paused_fibers   := RingQueue[&FiberContext].new()

    mutex           : Mutex
    threads         : Array[Thread]
    active_threads  := 0

    error_handler   : &ErrorHandler
    string_database : StringDatabase

    interp          : &Interpreter

    all_nodes       := Array[&AstNode].create()
}

impl Drop for Compiler {
    drop :: (ref Self) {
        for f : fibers {
            Memory.drop(f.fiber)
        }
    }
}

impl Compiler {
    new :: (thread_count: int, error_handler: &ErrorHandler) -> Rc[Compiler] {
        comp := Rc[Compiler].new(Compiler(
            mutex           = Mutex.new()
            threads         = Array[Thread].create()
            error_handler   = error_handler
            string_database = StringDatabase.new()
            interp          = Interpreter.new()
        ))
        comp.get().interp.printer = cast comp.get().print
        for 0..thread_count {
            comp.get().threads.add(Thread.new(cast comp.get().thread_func))
        }
        return comp
    }

    lock :: (ref Self) {
        if threads.get_length() > 1 then mutex.lock()
    }

    release :: (ref Self) {
        if threads.get_length() > 1 then mutex.release()
    }

    add_job :: (ref Self, job: $T) {
        ptr := mem.alloc(T)
        <<ptr = job
        jobs.push(ptr)
    }

    run_job :: (ref Self, context: &FiberContext) {
        match ref <<context.job {
            LoadFileJob($job) -> load_file(context, job)
            CompileGlobalNodeJob($job) -> compile_global_node(context, job)
        }
    }

    print :: (ref Self, format: string, args: []&any = [], category: string = "console") {
        io.formatln(format, args)
    }

    get_function :: (ref Self, name: string) -> &AstFunction {
        for node : all_nodes {
            decl := cast(&AstConstDecl) node
            func := cast(&AstFunction) &decl.value
            if decl.name.value == name {
                return func
            }
        }

        return null
    }

    compile_global_node :: (ref Self, context: &FiberContext, job: ref CompileGlobalNodeJob) {
        node := job.node
        io.formatln("[{}] [Job] CompileGlobalNode #{}", [context.thread, node.id])

        decl := cast(&AstConstDecl) node
        name := decl.name.value
        func := cast(&AstFunction) &decl.value

        allocator := DEFAULT_STD_HEAP_ALLOCATOR
        code_generator := ByteCodeGenerator.new(string_database, <<error_handler, &allocator)
        code_generator.get().generate_code_for_function(func, name)
        interp.register_function(name, func.bytecode)

        if name == "Main" {
            foo := get_function("foo")
            bar := get_function("bar")

            job.wait_for_bytecode(foo)
            job.wait_for_bytecode(bar)

            io.formatln("[{}] [Job] CompileGlobalNode #{}: calling main", [context.thread, node.id])
            interp.call("Main")
            interp.run()
        }

        io.formatln("[{}] [Job] CompileGlobalNode #{}: done", [context.thread, node.id])
    }

    load_file :: (ref Self, context: &FiberContext, job: ref LoadFileJob) {
        io.formatln("[{}] [Job] LoadFile '{}'", [context.thread, job.path])

        lexer := Lexer.from_file(job.path.slice(), self.string_database)
        match lexer {
            Ok($lexer) -> {
                allocator := DEFAULT_STD_HEAP_ALLOCATOR
                parser := Parser.new(lexer, error_handler, &allocator)

                loop {
                    decl := parser.parse_constant_declaration()
                    if decl == null then break
                    dump := dump_ast(<<decl)
                    // io.println(dump)

                    all_nodes.add(decl)
                    add_job(CompileGlobalNodeJob(node = decl))
                }
            }

            Err(_) -> {
                
            }
        }
    }
}

impl Compiler {
    start_compilation :: (ref Self) {
        // io.printfln("[compiler] compiling {} statements with {} threads", (exprs.get_length(), threads.get_length()))

        for threads {
            it.start()
        }
    }

    wait_until_done :: (ref Self) {
        handles := mem.alloc_raw(HANDLE, cast threads.get_length())

        for threads {
            handles[it_index] = it.data.handle
        }
        WaitForMultipleObjects(cast threads.get_length(), handles, 1, INFINITE)

        // for expr : exprs {
        //     if !expr.done {
        //         io.printfln("err: expr [{}] is not done", expr.id)
        //     }
        // }

        io.printfln("[compiler] finished compilation with {} fibers", fibers.get_length())
    }

    find_free_fiber :: (ref Self) -> &FiberContext {
        for f : fibers {
            if f.job == null and f.thread == -1 {
                return f
            }
        }
        {
            new_fiber := mem.alloc(FiberContext)
            <<new_fiber = FiberContext(Fiber.new(cast(Fn(&FiberContext)) self.fiber_func, new_fiber))
            fibers.add(new_fiber)
            return new_fiber
        }
    }

    fiber_func :: (ref Self, fiber_context: &FiberContext) {
        while true {
            while fiber_context.job == null {
                Fiber.yield()
            }

            fiber_context.job.progressed = false
            self.run_job(fiber_context)
            fiber_context.job = null
        }
    }

    thread_func :: (ref Self) {
        Fiber.init()
        thread_id := Thread.current().id

        current_fiber : &FiberContext = null
        while true #label main_loop {
            {
                self.lock()
                defer self.release()

                active_threads -= 1

                // if fiber made progress or finished, move all stuff from q2 to q
                if current_fiber != null {
                    current_fiber.thread = -1
                    if current_fiber.job == null or current_fiber.job.progressed {
                        while self.paused_fibers.count() > 0 {
                            self.waiting_fibers.push(self.paused_fibers.pop())
                        }
                    }

                    // if still not done, push in q2
                    if current_fiber.job != null {
                        self.paused_fibers.push(current_fiber)
                    }

                    current_fiber = null
                }

                if self.waiting_fibers.count() == 0 {
                    if self.jobs.count() > 0 {
                        job  := self.jobs.pop()
                        fiber := self.find_free_fiber()
                        fiber.job = job
                        self.waiting_fibers.push(fiber)

                    //*
                    } else if self.paused_fibers.count() > 0 {
                        if self.active_threads > 0 then continue
                        self.waiting_fibers.push(self.paused_fibers.pop())
                    // */

                    } else {
                        break main_loop
                    }
                }

                current_fiber = self.waiting_fibers.pop()
                current_fiber.thread = thread_id
                active_threads += 1
            }

            current_fiber.fiber.resume()
        }
    }
}
