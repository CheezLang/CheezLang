use import string_database

use import std.string
use import std.unicode
use import std.printable
use import std.io.fs
C  :: import std.c
io :: import std.io

#export_scope

Lexer :: struct {
    text_string : String
    text        : string
    location    : Location
    peek        : Option[Token]
    string_db   : ref StringDatabase

    // interned keywords
    KwLambda   : string
    KwReturn   : string
    KwRef      : string
    Kwfn       : string
    KwFn       : string
    KwStruct   : string
    KwEnum     : string
    KwImpl     : string
    KwIf       : string
    KwElse     : string
    KwFor      : string
    KwWhile    : string
    KwLoop     : string
    KwAnd      : string
    KwOr       : string
    KwTrue     : string
    KwFalse    : string
    KwNull     : string
    KwUsing    : string
    KwDefer    : string
    KwMatch    : string
    KwBreak    : string
    KwContinue : string
    KwTrait    : string
    KwCast     : string
    KwConst    : string
    KwDefault  : string
    KwPub      : string
    KwThen     : string
    KwDo       : string
    KwMut      : string
    KwImport   : string
}

impl Lexer {
    from_raw_string :: (content: string, string_db: ref StringDatabase) -> Lexer {
        return from_string(String.from_string(content), string_db)
    }

    // i dont know why, but for some reason when I enable trace-stack this function crashes
    // but with #nostacktrace it works...
    // - NO, 09.12.19
    from_string :: (content: String, string_db: ref StringDatabase) -> Lexer #nostacktrace {
        txt := content.slice()
        return Lexer(
            text_string = content
            text = txt
            location = Location(
                file = "string"
                byte_index  = 0
                byte_length = 1
                line        = 1
                column      = 1
            )
            peek          = None
            string_db     = string_db

            KwLambda   = string_db.intern("lambda")
            KwReturn   = string_db.intern("return")
            KwRef      = string_db.intern("ref")
            Kwfn       = string_db.intern("fn")
            KwFn       = string_db.intern("fn")
            KwStruct   = string_db.intern("struct")
            KwEnum     = string_db.intern("enum")
            KwImpl     = string_db.intern("impl")
            KwIf       = string_db.intern("if")
            KwElse     = string_db.intern("else")
            KwFor      = string_db.intern("for")
            KwWhile    = string_db.intern("while")
            KwLoop     = string_db.intern("loop")
            KwAnd      = string_db.intern("and")
            KwOr       = string_db.intern("or")
            KwTrue     = string_db.intern("true")
            KwFalse    = string_db.intern("false")
            KwNull     = string_db.intern("null")
            KwUsing    = string_db.intern("using")
            KwDefer    = string_db.intern("defer")
            KwMatch    = string_db.intern("match")
            KwBreak    = string_db.intern("break")
            KwContinue = string_db.intern("continue")
            KwTrait    = string_db.intern("trait")
            KwCast     = string_db.intern("cast")
            KwConst    = string_db.intern("const")
            KwDefault  = string_db.intern("default")
            KwPub      = string_db.intern("pub")
            KwThen     = string_db.intern("then")
            KwDo       = string_db.intern("do")
            KwMut      = string_db.intern("mut")
            KwImport   = string_db.intern("import")
        )
    }

    from_file :: (filename: string, string_db: ref StringDatabase) -> Result[Lexer, ()] {
        content := try_with(read_file(filename), {return Err(())})
        l := Lexer.from_string(content, string_db)
        l.location.file = filename
        return Ok(l)
    }

    expect_token :: (ref Self, typ: TokenType) -> bool, Token {
        token := next_token()
        if int(token.ttype) == int(typ) {
            return true, token
        } else {
            return false, token
        }
    }

    peek_token :: (ref Self) -> Token {
        return match peek {
            Some($tok) -> tok

            None -> {
                tok := next_token()
                peek = Some(tok)
                tok
            }
        }
    }

    next_token :: (ref Self) -> Token {
        match peek {
            Some($t) -> {
                peek = None
                return t
            }
        }

        match skip_newlines_and_comments() {
            Some($loc) -> {
                return Token(
                    ttype = TokenType.NewLine
                    location = loc
                    suffix = None
                    data = TokenData.None
                )
            }
        }

        return read_token()
    }

    read_token :: (ref Self) -> Token {
        token := Token(
            ttype = TokenType.EOF
            data = TokenData.None
            location = location
            suffix = None
        )
        token.location.byte_length = 0

        if location.byte_index >= text.bytes.length {
            return token
        }

        curr, curr_len := {
            x := peek_char(0)
            x[0], int(x[1])
        }
        next, next_len := {
            x := peek_char(1)
            x[0], int(x[1])
        }

        match curr, next {
            '<', '-' -> simple_token(token, TokenType.ReverseArrow,   curr_len + next_len, 2)
            '-', '>' -> simple_token(token, TokenType.Arrow,          curr_len + next_len, 2)
            '=', '>' -> simple_token(token, TokenType.DoubleArrow,    curr_len + next_len, 2)
            '=', '=' -> simple_token(token, TokenType.DoubleEqual,    curr_len + next_len, 2)
            '!', '=' -> simple_token(token, TokenType.NotEqual,       curr_len + next_len, 2)
            '<', '=' -> simple_token(token, TokenType.LessEqual,      curr_len + next_len, 2)
            '<', '<' -> simple_token(token, TokenType.LessLess,       curr_len + next_len, 2)
            '>', '=' -> simple_token(token, TokenType.GreaterEqual,   curr_len + next_len, 2)
            '+', '=' -> simple_token(token, TokenType.AddEq,          curr_len + next_len, 2)
            '-', '=' -> simple_token(token, TokenType.SubEq,          curr_len + next_len, 2)
            '*', '=' -> simple_token(token, TokenType.MulEq,          curr_len + next_len, 2)
            '/', '=' -> simple_token(token, TokenType.DivEq,          curr_len + next_len, 2)
            '%', '=' -> simple_token(token, TokenType.ModEq,          curr_len + next_len, 2)
            '.', '.' -> simple_token(token, TokenType.PeriodPeriod,   curr_len + next_len, 2)
            ':', _   -> simple_token(token, TokenType.Colon,          curr_len, 1)
            ';', _   -> simple_token(token, TokenType.Semicolon,      curr_len, 1)
            '.', _   -> simple_token(token, TokenType.Period,         curr_len, 1)
            '=', _   -> simple_token(token, TokenType.Equal,          curr_len, 1)
            '(', _   -> simple_token(token, TokenType.OpenParen,      curr_len, 1)
            ')', _   -> simple_token(token, TokenType.ClosingParen,   curr_len, 1)
            '{', _   -> simple_token(token, TokenType.OpenBrace,      curr_len, 1)
            '}', _   -> simple_token(token, TokenType.ClosingBrace,   curr_len, 1)
            '[', _   -> simple_token(token, TokenType.OpenBracket,    curr_len, 1)
            ']', _   -> simple_token(token, TokenType.ClosingBracket, curr_len, 1)
            ',', _   -> simple_token(token, TokenType.Comma,          curr_len, 1)
            '&', _   -> simple_token(token, TokenType.Ampersand,      curr_len, 1)
            '*', _   -> simple_token(token, TokenType.Asterisk,       curr_len, 1)
            '/', _   -> simple_token(token, TokenType.ForwardSlash,   curr_len, 1)
            '^', _   -> simple_token(token, TokenType.Caret,           curr_len, 1)
            '+', _   -> simple_token(token, TokenType.Plus,           curr_len, 1)
            '%', _   -> simple_token(token, TokenType.Percent,        curr_len, 1)
            '-', _   -> simple_token(token, TokenType.Minus,          curr_len, 1)
            '<', _   -> simple_token(token, TokenType.Less,           curr_len, 1)
            '>', _   -> simple_token(token, TokenType.Greater,        curr_len, 1)
            '!', _   -> simple_token(token, TokenType.Bang,           curr_len, 1)
            '|', _   -> simple_token(token, TokenType.Pipe,           curr_len, 1)

            '"', _  -> {
                parse_string_literal(token, TokenType.StringLiteral, '"')
                parse_suffix(token)
            }
            '`'', _ -> {
                parse_string_literal(token, TokenType.CharLiteral, '`'')
                parse_suffix(token)
            }

            // identifiers and keywords
            '$', _ -> {
                location.byte_index += curr_len
                location.column += 1
                parse_identifier(token, TokenType.DollarIdentifier)
            }
            '#', _ ->  {
                location.byte_index += curr_len
                location.column += 1
                parse_identifier(token, TokenType.HashIdentifier)
            }
            '@', _ ->  {
                location.byte_index += curr_len
                location.column += 1
                parse_identifier(token, TokenType.AtSignIdentifier)
            }
            $x, _ if is_ident_begin(x) -> {
                parse_identifier(token, TokenType.Identifier)
                check_keywords(token)
            }

            // number literal
            $x, _ if is_digit(x) -> {
                parse_number_literal(token)
                parse_suffix(token)
            }

            _, _ -> {
                token.ttype = TokenType.Unknown
                location.byte_index += 1
            }
        }

        token.location.byte_length = location.byte_index - token.location.byte_index

        return token
    }

    parse_number_literal :: (ref Self, token: ref Token) {
        token.ttype = TokenType.NumberLiteral
        base := 10
        str := {
            cap :: 128
            raw := @alloca(u8, cap)
            str := String.from_raw_ptr(raw, cap)
            str
        }

        is_float := false

        LexerNumberState :: enum #copy {
            Error
            Init
            Done
            Z
            X
            B
            DecDigit
            Dec_
            BinDigit
            Bin_
            HexDigit
            Hex_
            FloatPoint
            FloatDigit
            Float_
        }

        use LexerNumberState

        state := Init
        while location.byte_index < text.bytes.length {
            c, c_len := peek_char(0)
            next, _  := peek_char(1)

            match state {
                Error -> break
                Done  -> break

                Init  -> {
                    if c == '0' {
                        str += c
                        state = Z
                    } else if is_digit(c) {
                        str += c
                        state = DecDigit
                    }
                }

                Z -> match c {
                    'x' -> {
                        base = 16
                        str.resize(0)
                        state = X
                    }
                    'b' -> {
                        base = 2
                        str.resize(0)
                        state = B
                    }
                    '.' if next != '.' -> {
                        str += c
                        state = FloatPoint
                    }
                    $x if is_digit(x) -> {
                        str += x
                        state = DecDigit
                    }
                    '_' -> {
                        state = Dec_
                    }
                    _ -> {
                        state = Done
                    }
                }

                DecDigit -> match c {
                    '.' if next != '.' -> {
                        str += c
                        state = FloatPoint
                    }
                    '_' -> {
                        state = Dec_
                    }
                    $x if is_digit(x) -> {
                        str += c
                    }
                    _ -> {
                        state = Done
                    }
                }

                Dec_ -> match c {
                    $x if is_digit(x) -> {
                        str += c
                        state = DecDigit
                    }
                    _ -> {
                        state = Error
                    }
                }

                FloatPoint -> {
                    is_float = true
                    if is_digit(c) {
                        str += c
                        state = FloatDigit
                    } else {
                        state = Error
                    }
                }

                FloatDigit -> match c {
                    $c if is_digit(c) -> {
                        str += c
                    }
                    '_' -> {
                        state = Float_
                    }
                    $_ -> {
                        state = Done
                    }
                }

                Float_ -> match c {
                    $x if is_digit(x) -> {
                        str += c
                        state = FloatDigit
                    }
                    _ -> {
                        state = Error
                    }
                }

                X -> match c {
                    $c if is_hex_digit(c) -> {
                        str += c
                        state = HexDigit
                    }
                    $_ -> {
                        state = Error
                    }
                }

                HexDigit -> match c {
                    $c if is_hex_digit(c) -> {
                        str += c
                    }
                    '_' -> {
                        state = Hex_
                    }
                    $_ -> {
                        state = Done
                    }
                }

                Hex_ -> match c {
                    $x if is_hex_digit(x) -> {
                        str += c
                        state = HexDigit
                    }
                    _ -> {
                        state = Error
                    }
                }

                B -> match c {
                    $c if is_binary_digit(c) -> {
                        str += c
                        state = BinDigit
                    }
                    $_ -> {
                        state = Error
                    }
                }

                BinDigit -> match c {
                    $c if is_binary_digit(c) -> {
                        str += c
                    }
                    '_' -> {
                        state = Bin_
                    }
                    $_ -> {
                        state = Done
                    }
                }

                Bin_ -> match c {
                    $x if is_binary_digit(x) -> {
                        str += c
                        state = BinDigit
                    }
                    _ -> {
                        state = Error
                    }
                }
            }

            match state {
                Done -> break
                Error -> break
                $_   -> {
                    location.byte_index += int(c_len)
                    location.column += 1
                }
            }
        }

        match state {
            Error -> {
                token.ttype = TokenType.Error
                token.data = TokenData.String("Invalid number literal")
                return
            }
        }

        str += '`0'

        if is_float {
            d := C.strtod(cast str.get_raw(), null)
            token.data = TokenData.Double(d)
        } else {
            i := C.strtol(cast str.get_raw(), null, cast base)
            token.data = TokenData.Integer(i)
        }
    }

    parse_suffix :: (ref Self, token: ref Token) {
        if is_ident_begin(peek_char(0)[0]) {
            start := location.byte_index
            while location.byte_index < text.bytes.length {
                c, c_len := peek_char(0)
                if !is_ident_char(c) then break
                location.byte_index += int(c_len)
                location.column += 1
            }

            token.suffix = Some(text[start..location.byte_index])
        }
    }

    simple_token :: (ref Self, token: ref Token, ttype: TokenType, len: int, chars: int) {
        token.ttype = ttype
        location.byte_index += len
        location.column += chars
    }

    parse_identifier :: (ref Self, token: ref Token, ttype: TokenType) {
        token.ttype = ttype
        start := location.byte_index

        while location.byte_index < text.bytes.length {
            c, c_len := peek_char(0)
            if !is_ident_char(c) then break
            location.byte_index += int(c_len)
            location.column += 1
        }

        str := text[start..location.byte_index]
        token.data = TokenData.String(string_db.intern(str))
    }

    parse_string_literal :: (ref Self, token: ref Token, ttype: TokenType, end: char) {
        token.ttype = ttype
        location.byte_index += 1
        location.column += 1
        start := location.byte_index

        foundEnd := false
        while location.byte_index < text.bytes.length {
            c, c_len := peek_char(0)
            location.byte_index += int(c_len)
            location.column += 1

            if c == end {
                foundEnd = true
                break
            } else if c == '``' {
                if location.byte_index >= text.bytes.length {
                    // TODO: report error
                    break
                }

                location.byte_index += int(c_len)
                location.column += 1
            }

            if c == '`n' {
                location.column = 1
                location.line += 1
            }
        }

        if !foundEnd {
            // TODO: report
        }

        str := text[start .. location.byte_index - 1]
        token.data = TokenData.String(string_db.intern(str))
    }

    skip_newlines_and_comments :: (ref Self) -> loc: Option[Location] {
        loc = None

        while location.byte_index < text.bytes.length {
            curr, curr_len := peek_char(0)
            next, next_len := peek_char(1)

            if curr == '/' and next == '*' {
                parse_multi_line_comment()
            } else if curr == '/' and next == '/' {
                parse_single_line_comment()
            } else if curr == ' ' or curr == '`t' {
                location.byte_index += int(curr_len)
                location.column += 1
            } else if curr == '`r' {
                location.byte_index += int(curr_len)
                location.column += 1
            } else if curr == '`n' {
                match loc {
                    None -> {
                        loc = Some(location)
                    }
                }

                location.line += 1
                location.byte_index += int(curr_len)
                location.column = 1
            } else {
                break
            }
        }
    }

    peek_char :: (ref Self, offset: int) -> char, i32 {
        index := location.byte_index
        while offset > 0, offset -= 1 {
            _, len := Utf8.decode(text.slice().bytes[index..text.bytes.length])
            index += int(len)
        }
        if index >= text.bytes.length {
            return char(0), 0
        }

        return Utf8.decode(text.bytes[index..text.bytes.length])
    }

    parse_multi_line_comment :: (ref Self) {
        level := 0
        while location.byte_index < text.bytes.length {
            curr, curr_len := peek_char(0)
            next, next_len := peek_char(1)

            if curr == '/' and next == '*' {
                location.byte_index += int(next_len)
                location.column += 1
                level += 1
            } else if curr == '*' and next == '/' {
                location.byte_index += int(next_len)
                location.column += 1
                level -= 1

                if level == 0 {
                    break
                }
            } else if curr == '\n' {
                location.line += 1
                location.column = 1
            }

            location.byte_index += int(curr_len)
            location.column += 1
        }
    }

    parse_single_line_comment :: (ref Self) {
        while location.byte_index < text.bytes.length {
            next, len := peek_char(0)
            if next == '`n' {
                break
            }

            location.byte_index += int(len)
            location.column += 1
        }
    }

    check_keywords :: (ref Self, token: ref Token) {
        match token.data {
            TokenData.String($str) -> {
                token.ttype =
                    if str == KwLambda          then TokenType.KwLambda
                    else if str == KwReturn     then TokenType.KwReturn
                    else if str == KwRef        then TokenType.KwRef
                    else if str == Kwfn         then TokenType.Kwfn
                    else if str == KwFn         then TokenType.KwFn
                    else if str == KwStruct     then TokenType.KwStruct
                    else if str == KwEnum       then TokenType.KwEnum
                    else if str == KwImpl       then TokenType.KwImpl
                    else if str == KwIf         then TokenType.KwIf
                    else if str == KwElse       then TokenType.KwElse
                    else if str == KwFor        then TokenType.KwFor
                    else if str == KwWhile      then TokenType.KwWhile
                    else if str == KwLoop       then TokenType.KwLoop
                    else if str == KwAnd        then TokenType.KwAnd
                    else if str == KwOr         then TokenType.KwOr
                    else if str == KwTrue       then TokenType.KwTrue
                    else if str == KwFalse      then TokenType.KwFalse
                    else if str == KwNull       then TokenType.KwNull
                    else if str == KwUsing      then TokenType.KwUsing
                    else if str == KwDefer      then TokenType.KwDefer
                    else if str == KwMatch      then TokenType.KwMatch
                    else if str == KwBreak      then TokenType.KwBreak
                    else if str == KwContinue   then TokenType.KwContinue
                    else if str == KwTrait      then TokenType.KwTrait
                    else if str == KwCast       then TokenType.KwCast
                    else if str == KwConst      then TokenType.KwConst
                    else if str == KwDefault    then TokenType.KwDefault
                    else if str == KwPub        then TokenType.KwPub
                    else if str == KwThen       then TokenType.KwThen
                    else if str == KwDo         then TokenType.KwDo
                    else if str == KwMut        then TokenType.KwMut
                    else if str == KwImport     then TokenType.KwImport
                    else token.ttype
            }
        }
    }
}

// token
Location :: struct #copy {
    file        : string = default
    byte_index  : int    = default
    byte_length : int    = default
    line        : int    = default
    column      : int    = default
}

Token :: struct #copy {
    ttype   : TokenType
    location: Location
    suffix  : Option[string]
    data    : TokenData
}

TokenData :: enum #copy {
    None
    String  : string
    Integer : int
    Double  : double
}

impl Printable for Location {
    print :: (ref Self, str: ref String, format: string) {
        str.appendf("{}:{}", (line, column))
    }
}

impl Printable for Token {
    print :: (ref Self, str: ref String, format: string) {
        str.appendf("{} ({})", (ttype, location))
        match data {
            TokenData.String($s) -> str.appendf(" String({})", s)
            TokenData.Integer($s) -> str.appendf(" Int({})", s)
            TokenData.Double($s) -> str.appendf(" Double({})", s)
        }

        match suffix {
            Some($s) -> str.appendf(" Suffix(`"{}`")", (s))
        }
    }
}

impl Printable for TokenType {
    print :: (ref Self, str: ref String, format: string) {
        use TokenType

        str += cast(string)match self {
            Error             -> "Error"
            Unknown           -> "Unknown"
            NewLine           -> "NewLine"
            EOF               -> "EOF"
            StringLiteral     -> "StringLiteral"
            CharLiteral       -> "CharLiteral"
            NumberLiteral     -> "NumberLiteral"
            Identifier        -> "Identifier"
            DollarIdentifier  -> "DollarIdentifier"
            HashIdentifier    -> "HashIdentifier"
            AtSignIdentifier  -> "AtSignIdentifier"
            ReplaceIdentifier -> "ReplaceIdentifier"
            Semicolon         -> "Semicolon"
            Colon             -> "Colon"
            Comma             -> "Comma"
            Period            -> "Period"
            PeriodPeriod      -> "PeriodPeriod"
            Equal             -> "Equal"
            Ampersand         -> "Ampersand"
            Bang              -> "Bang"
            Caret             -> "Caret"
            Plus              -> "Plus"
            Minus             -> "Minus"
            Asterisk          -> "Asterisk"
            ForwardSlash      -> "ForwardSlash"
            Percent           -> "Percent"
            AddEq             -> "AddEq"
            SubEq             -> "SubEq"
            MulEq             -> "MulEq"
            DivEq             -> "DivEq"
            ModEq             -> "ModEq"
            Less              -> "Less"
            LessEqual         -> "LessEqual"
            Greater           -> "Greater"
            GreaterEqual      -> "GreaterEqual"
            DoubleEqual       -> "DoubleEqual"
            NotEqual          -> "NotEqual"
            ReverseArrow      -> "ReverseArrow"
            Arrow             -> "Arrow"
            DoubleArrow       -> "DoubleArrow"
            LessLess          -> "LessLess"
            OpenParen         -> "OpenParen"
            ClosingParen      -> "ClosingParen"
            OpenBrace         -> "OpenBrace"
            ClosingBrace      -> "ClosingBrace"
            OpenBracket       -> "OpenBracket"
            ClosingBracket    -> "ClosingBracket"
            Pipe              -> "Pipe"
            KwLambda          -> "KwLambda"
            KwReturn          -> "KwReturn"
            KwRef             -> "KwRef"
            Kwfn              -> "Kwfn"
            KwFn              -> "KwFn"
            KwStruct          -> "KwStruct"
            KwEnum            -> "KwEnum"
            KwImpl            -> "KwImpl"
            KwIf              -> "KwIf"
            KwElse            -> "KwElse"
            KwFor             -> "KwFor"
            KwWhile           -> "KwWhile"
            KwLoop            -> "KwLoop"
            KwAnd             -> "KwAnd"
            KwOr              -> "KwOr"
            KwTrue            -> "KwTrue"
            KwFalse           -> "KwFalse"
            KwNull            -> "KwNull"
            KwUsing           -> "KwUsing"
            KwDefer           -> "KwDefer"
            KwMatch           -> "KwMatch"
            KwBreak           -> "KwBreak"
            KwContinue        -> "KwContinue"
            KwTrait           -> "KwTrait"
            KwCast            -> "KwCast"
            KwConst           -> "KwConst"
            KwDefault         -> "KwDefault"
            KwPub             -> "KwPub"
            KwThen            -> "KwThen"
            KwDo              -> "KwDo"
            KwMut             -> "KwMut"
            KwImport          -> "KwImport"
        }
    }
}

TokenType :: enum #copy {
    Error
    Unknown
    NewLine
    EOF
    StringLiteral
    CharLiteral
    NumberLiteral
    Identifier
    DollarIdentifier
    HashIdentifier
    AtSignIdentifier
    ReplaceIdentifier
    Semicolon
    Colon
    Comma
    Period
    PeriodPeriod
    Equal
    Ampersand
    Bang
    Caret
    Plus
    Minus
    Asterisk
    ForwardSlash
    Percent
    AddEq
    SubEq
    MulEq
    DivEq
    ModEq
    Less
    LessEqual
    Greater
    GreaterEqual
    DoubleEqual
    NotEqual
    ReverseArrow
    Arrow
    DoubleArrow
    LessLess
    OpenParen
    ClosingParen
    OpenBrace
    ClosingBrace
    OpenBracket
    ClosingBracket
    Pipe
    KwLambda
    KwReturn
    KwRef
    Kwfn
    KwFn
    KwStruct
    KwEnum
    KwImpl
    KwIf
    KwElse
    KwFor
    KwWhile
    KwLoop
    KwAnd
    KwOr
    KwTrue
    KwFalse
    KwNull
    KwUsing
    KwDefer
    KwMatch
    KwBreak
    KwContinue
    KwTrait
    KwCast
    KwConst
    KwDefault
    KwPub
    KwThen
    KwDo
    KwMut
    KwImport
}

#file_scope
is_ident_begin :: (c: char) -> bool {
    return (c >= 'a' and c <= 'z') or (c >= 'A' and c <= 'Z') or (c == '_') or u32(c) > 127
}

is_ident_char :: (c: char) -> bool {
    return is_ident_begin(c) or (c >= '0' and c <= '9')
}

is_digit :: (c: char) -> bool {
    return c >= '0' and c <= '9'
}

is_hex_digit :: (c: char) -> bool {
    return (c >= '0' and c <= '9') or (c >= 'a' and c <= 'f') or (c >= 'A' and c <= 'F')
}

is_binary_digit :: (c: char) -> bool {
    return c >= '0' and c <= '1'
}