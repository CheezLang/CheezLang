use import string_database
use import error_handler

use import std.string
use import std.unicode
use import std.printable
use import std.io.fs
use import std.rc

C  :: import std.c
io :: import std.io

#export_scope

Lexer :: struct {
    text        : string
    location    : Location
    peek        : Option[Token]
    string_db   : ref StringDatabase

    // interned keywords
    KwLambda   : string
    KwReturn   : string
    KwRef      : string
    Kwfn       : string
    KwFn       : string
    KwStruct   : string
    KwEnum     : string
    KwImpl     : string
    KwIf       : string
    KwElse     : string
    KwFor      : string
    KwWhile    : string
    KwLoop     : string
    KwAnd      : string
    KwOr       : string
    KwTrue     : string
    KwFalse    : string
    KwNull     : string
    KwUsing    : string
    KwDefer    : string
    KwMatch    : string
    KwBreak    : string
    KwContinue : string
    KwTrait    : string
    KwCast     : string
    KwConst    : string
    KwDefault  : string
    KwPub      : string
    KwThen     : string
    KwDo       : string
    KwMut      : string
    KwImport   : string
}

impl TextProvider for Lexer {
    get_text :: (ref Self, filename: string) -> string {
        return text
    }
}

impl Lexer {
    // i dont know why, but for some reason when I enable trace-stack this function crashes
    // but with #nostacktrace it works...
    // - NO, 09.12.19
    from_string :: (content: string, string_db: ref StringDatabase) -> Rc[Lexer] #nostacktrace {
        return Rc[Lexer].new(Lexer(
            text = content
            location = Location(
                file = "string"
                byte_index  = 0
                byte_length = 1
                line        = 1
                column      = 1
            )
            peek          = None
            string_db     = string_db

            KwLambda   = string_db.intern("lambda")
            KwReturn   = string_db.intern("return")
            KwRef      = string_db.intern("ref")
            Kwfn       = string_db.intern("fn")
            KwFn       = string_db.intern("fn")
            KwStruct   = string_db.intern("struct")
            KwEnum     = string_db.intern("enum")
            KwImpl     = string_db.intern("impl")
            KwIf       = string_db.intern("if")
            KwElse     = string_db.intern("else")
            KwFor      = string_db.intern("for")
            KwWhile    = string_db.intern("while")
            KwLoop     = string_db.intern("loop")
            KwAnd      = string_db.intern("and")
            KwOr       = string_db.intern("or")
            KwTrue     = string_db.intern("true")
            KwFalse    = string_db.intern("false")
            KwNull     = string_db.intern("null")
            KwUsing    = string_db.intern("using")
            KwDefer    = string_db.intern("defer")
            KwMatch    = string_db.intern("match")
            KwBreak    = string_db.intern("break")
            KwContinue = string_db.intern("continue")
            KwTrait    = string_db.intern("trait")
            KwCast     = string_db.intern("cast")
            KwConst    = string_db.intern("const")
            KwDefault  = string_db.intern("default")
            KwPub      = string_db.intern("pub")
            KwThen     = string_db.intern("then")
            KwDo       = string_db.intern("do")
            KwMut      = string_db.intern("mut")
            KwImport   = string_db.intern("import")
        ))
    }

    from_file :: (filename: string, string_db: ref StringDatabase) -> Result[Rc[Lexer], ()] {
        content := {
            content := try_with(read_file(filename), {return Err(())})
            string_db.intern(content.slice())
        }
        l := Lexer.from_string(content.slice(), string_db)
        l.get().location.file = filename
        return Ok(l)
    }

    expect_token :: (ref Self, typ: TokenType) -> bool, Token {
        token := next_token()
        if int(token.typ) == int(typ) {
            return true, token
        } else {
            return false, token
        }
    }

    peek_token :: (ref Self) -> ref Token {
        return match ref peek {
            Some($tok) -> tok

            None -> {
                tok := next_token()
                peek = Some(tok)
                peek.Some
            }
        }
    }

    next_token :: (ref Self) -> Token {
        match peek {
            Some($t) -> {
                peek = None
                return t
            }
        }

        match skip_newlines_and_comments() {
            Some($loc) -> {
                return Token(
                    typ = TokenType.NewLine
                    location = loc
                    suffix = None
                    data = TokenData.None
                )
            }
        }

        return read_token()
    }

    skip_whitespace :: (ref Self) {
        while true {
            tok := self.peek_token()

            match tok.typ {
                TokenType.NewLine -> {
                    self.next_token()
                }

                $_ -> {
                    break
                }
            }
        }
    }

    skip_line :: (ref Self) {
        while true {
            tok := self.next_token()

            match tok.typ {
                TokenType.EOF -> {
                    return
                }
                TokenType.NewLine -> {
                    return
                }
            }
        }
    }

    read_token :: (ref Self) -> Token {
        token := Token(
            typ = TokenType.EOF
            data = TokenData.None
            location = location
            suffix = None
        )

        token.location.byte_length = 0

        if location.byte_index >= text.bytes.length {
            return token
        }

        curr, curr_len := {
            x := peek_char(0)
            x[0], int(x[1])
        }
        next, next_len := {
            x := peek_char(1)
            x[0], int(x[1])
        }

        match curr, next {
            '<', '-' -> simple_token(token, TokenType.ReverseArrow,   curr_len + next_len, 2)
            '-', '>' -> simple_token(token, TokenType.Arrow,          curr_len + next_len, 2)
            '=', '>' -> simple_token(token, TokenType.DoubleArrow,    curr_len + next_len, 2)
            '=', '=' -> simple_token(token, TokenType.DoubleEqual,    curr_len + next_len, 2)
            '!', '=' -> simple_token(token, TokenType.NotEqual,       curr_len + next_len, 2)
            '<', '=' -> simple_token(token, TokenType.LessEqual,      curr_len + next_len, 2)
            '<', '<' -> simple_token(token, TokenType.LessLess,       curr_len + next_len, 2)
            '>', '=' -> simple_token(token, TokenType.GreaterEqual,   curr_len + next_len, 2)
            '+', '=' -> simple_token(token, TokenType.AddEq,          curr_len + next_len, 2)
            '-', '=' -> simple_token(token, TokenType.SubEq,          curr_len + next_len, 2)
            '*', '=' -> simple_token(token, TokenType.MulEq,          curr_len + next_len, 2)
            '/', '=' -> simple_token(token, TokenType.DivEq,          curr_len + next_len, 2)
            '%', '=' -> simple_token(token, TokenType.ModEq,          curr_len + next_len, 2)
            '.', '.' -> simple_token(token, TokenType.PeriodPeriod,   curr_len + next_len, 2)
            ':', _   -> simple_token(token, TokenType.Colon,          curr_len, 1)
            ';', _   -> simple_token(token, TokenType.Semicolon,      curr_len, 1)
            '.', _   -> simple_token(token, TokenType.Period,         curr_len, 1)
            '=', _   -> simple_token(token, TokenType.Equal,          curr_len, 1)
            '(', _   -> simple_token(token, TokenType.OpenParen,      curr_len, 1)
            ')', _   -> simple_token(token, TokenType.ClosingParen,   curr_len, 1)
            '{', _   -> simple_token(token, TokenType.OpenBrace,      curr_len, 1)
            '}', _   -> simple_token(token, TokenType.ClosingBrace,   curr_len, 1)
            '[', _   -> simple_token(token, TokenType.OpenBracket,    curr_len, 1)
            ']', _   -> simple_token(token, TokenType.ClosingBracket, curr_len, 1)
            ',', _   -> simple_token(token, TokenType.Comma,          curr_len, 1)
            '&', _   -> simple_token(token, TokenType.Ampersand,      curr_len, 1)
            '*', _   -> simple_token(token, TokenType.Asterisk,       curr_len, 1)
            '/', _   -> simple_token(token, TokenType.ForwardSlash,   curr_len, 1)
            '^', _   -> simple_token(token, TokenType.Caret,           curr_len, 1)
            '+', _   -> simple_token(token, TokenType.Plus,           curr_len, 1)
            '%', _   -> simple_token(token, TokenType.Percent,        curr_len, 1)
            '-', _   -> simple_token(token, TokenType.Minus,          curr_len, 1)
            '<', _   -> simple_token(token, TokenType.Less,           curr_len, 1)
            '>', _   -> simple_token(token, TokenType.Greater,        curr_len, 1)
            '!', _   -> simple_token(token, TokenType.Bang,           curr_len, 1)
            '|', _   -> simple_token(token, TokenType.Pipe,           curr_len, 1)

            '"', _  -> {
                parse_string_literal(token, TokenType.StringLiteral, '"')
                parse_suffix(token)
            }
            '`'', _ -> {
                parse_string_literal(token, TokenType.CharLiteral, '`'')
                parse_suffix(token)
            }

            // identifiers and keywords
            '$', _ -> {
                location.byte_index += curr_len
                location.column += 1
                parse_identifier(token, TokenType.DollarIdentifier)
            }
            '#', _ ->  {
                location.byte_index += curr_len
                location.column += 1
                parse_identifier(token, TokenType.HashIdentifier)
            }
            '@', _ ->  {
                location.byte_index += curr_len
                location.column += 1
                parse_identifier(token, TokenType.AtSignIdentifier)
            }
            $x, _ if is_ident_begin(x) -> {
                parse_identifier(token, TokenType.Identifier)
                check_keywords(token)
            }

            // number literal
            $x, _ if is_digit(x) -> {
                parse_number_literal(token)
                parse_suffix(token)
            }

            _, _ -> {
                token.typ = TokenType.Unknown
                location.byte_index += 1
            }
        }

        token.location.byte_length = location.byte_index - token.location.byte_index
        token.location.end_line = location.line

        return token
    }

    parse_number_literal :: (ref Self, token: ref Token) {
        token.typ = TokenType.NumberLiteral
        base := 10
        str := {
            raw := @alloca(u8, 128)
            str := String.from_raw_ptr(raw.data, raw.length)
            str
        }

        is_float := false

        LexerNumberState :: enum #copy {
            Error
            Init
            Done
            Z
            X
            B
            DecDigit
            Dec_
            BinDigit
            Bin_
            HexDigit
            Hex_
            FloatPoint
            FloatDigit
            Float_
        }

        use LexerNumberState

        state := Init
        while location.byte_index < text.bytes.length {
            c, c_len := peek_char(0)
            next, _  := peek_char(1)

            match state {
                Error -> break
                Done  -> break

                Init  -> {
                    if c == '0' {
                        str += c
                        state = Z
                    } else if is_digit(c) {
                        str += c
                        state = DecDigit
                    }
                }

                Z -> match c {
                    'x' -> {
                        base = 16
                        str.resize(0)
                        state = X
                    }
                    'b' -> {
                        base = 2
                        str.resize(0)
                        state = B
                    }
                    '.' if next != '.' -> {
                        str += c
                        state = FloatPoint
                    }
                    $x if is_digit(x) -> {
                        str += x
                        state = DecDigit
                    }
                    '_' -> {
                        state = Dec_
                    }
                    _ -> {
                        state = Done
                    }
                }

                DecDigit -> match c {
                    '.' if next != '.' -> {
                        str += c
                        state = FloatPoint
                    }
                    '_' -> {
                        state = Dec_
                    }
                    $x if is_digit(x) -> {
                        str += c
                    }
                    _ -> {
                        state = Done
                    }
                }

                Dec_ -> match c {
                    $x if is_digit(x) -> {
                        str += c
                        state = DecDigit
                    }
                    _ -> {
                        state = Error
                    }
                }

                FloatPoint -> {
                    is_float = true
                    if is_digit(c) {
                        str += c
                        state = FloatDigit
                    } else {
                        state = Error
                    }
                }

                FloatDigit -> match c {
                    $c if is_digit(c) -> {
                        str += c
                    }
                    '_' -> {
                        state = Float_
                    }
                    $_ -> {
                        state = Done
                    }
                }

                Float_ -> match c {
                    $x if is_digit(x) -> {
                        str += c
                        state = FloatDigit
                    }
                    _ -> {
                        state = Error
                    }
                }

                X -> match c {
                    $c if is_hex_digit(c) -> {
                        str += c
                        state = HexDigit
                    }
                    $_ -> {
                        state = Error
                    }
                }

                HexDigit -> match c {
                    $c if is_hex_digit(c) -> {
                        str += c
                    }
                    '_' -> {
                        state = Hex_
                    }
                    $_ -> {
                        state = Done
                    }
                }

                Hex_ -> match c {
                    $x if is_hex_digit(x) -> {
                        str += c
                        state = HexDigit
                    }
                    _ -> {
                        state = Error
                    }
                }

                B -> match c {
                    $c if is_binary_digit(c) -> {
                        str += c
                        state = BinDigit
                    }
                    $_ -> {
                        state = Error
                    }
                }

                BinDigit -> match c {
                    $c if is_binary_digit(c) -> {
                        str += c
                    }
                    '_' -> {
                        state = Bin_
                    }
                    $_ -> {
                        state = Done
                    }
                }

                Bin_ -> match c {
                    $x if is_binary_digit(x) -> {
                        str += c
                        state = BinDigit
                    }
                    _ -> {
                        state = Error
                    }
                }
            }

            match state {
                Done -> break
                Error -> break
                $_   -> {
                    location.byte_index += int(c_len)
                    location.column += 1
                }
            }
        }

        match state {
            Error -> {
                token.typ = TokenType.Error
                token.data = TokenData.String("Invalid number literal")
                return
            }
        }

        str += '`0'

        if is_float {
            d := C.strtod(cast str.get_raw(), null)
            token.data = TokenData.Double(d)
        } else {
            i := C.strtol(cast str.get_raw(), null, cast base)
            token.data = TokenData.Integer(i)
        }
    }

    parse_suffix :: (ref Self, token: ref Token) {
        if is_ident_begin(peek_char(0)[0]) {
            start := location.byte_index
            while location.byte_index < text.bytes.length {
                c, c_len := peek_char(0)
                if !is_ident_char(c) then break
                location.byte_index += int(c_len)
                location.column += 1
            }

            token.suffix = Some(text[start..location.byte_index])
        }
    }

    simple_token :: (ref Self, token: ref Token, typ: TokenType, len: int, chars: int) {
        token.typ = typ
        location.byte_index += len
        location.column += chars
    }

    parse_identifier :: (ref Self, token: ref Token, typ: TokenType) {
        token.typ = typ
        start := location.byte_index

        while location.byte_index < text.bytes.length {
            c, c_len := peek_char(0)
            if !is_ident_char(c) then break
            location.byte_index += int(c_len)
            location.column += 1
        }

        str := text[start..location.byte_index]
        token.data = TokenData.String(string_db.intern(str))
    }

    parse_string_literal :: (ref Self, token: ref Token, typ: TokenType, end: char) {
        token.typ = typ
        location.byte_index += 1
        location.column += 1
        start := location.byte_index

        foundEnd := false
        while location.byte_index < text.bytes.length {
            c, c_len := peek_char(0)
            location.byte_index += int(c_len)
            location.column += 1

            if c == end {
                foundEnd = true
                break
            } else if c == '``' {
                if location.byte_index >= text.bytes.length {
                    // TODO: report error
                    break
                }

                location.byte_index += int(c_len)
                location.column += 1
            }

            if c == '`n' {
                location.column = 1
                location.line += 1
            }
        }

        if !foundEnd {
            // TODO: report
        }

        str := text[start .. location.byte_index - 1]
        token.data = TokenData.String(string_db.intern(str))
    }

    skip_newlines_and_comments :: (ref Self) -> loc: Option[Location] {
        loc = None

        while location.byte_index < text.bytes.length {
            curr, curr_len := peek_char(0)
            next, next_len := peek_char(1)

            if curr == '/' and next == '*' {
                parse_multi_line_comment()
            } else if curr == '/' and next == '/' {
                parse_single_line_comment()
            } else if curr == ' ' or curr == '`t' {
                location.byte_index += int(curr_len)
                location.column += 1
            } else if curr == '`r' {
                location.byte_index += int(curr_len)
                location.column += 1
            } else if curr == '`n' {
                match loc {
                    None -> {
                        loc = Some(location)
                    }
                }

                location.line += 1
                location.byte_index += int(curr_len)
                location.column = 1
            } else {
                break
            }
        }
    }

    peek_char :: (ref Self, offset: int) -> char, i32 {
        index := location.byte_index
        while offset > 0, offset -= 1 {
            _, len := Utf8.decode(text.slice().bytes[index..text.bytes.length])
            index += int(len)
        }
        if index >= text.bytes.length {
            return char(0), 0
        }

        return Utf8.decode(text.bytes[index..text.bytes.length])
    }

    parse_multi_line_comment :: (ref Self) {
        level := 0
        while location.byte_index < text.bytes.length {
            curr, curr_len := peek_char(0)
            next, next_len := peek_char(1)

            if curr == '/' and next == '*' {
                location.byte_index += int(next_len)
                location.column += 1
                level += 1
            } else if curr == '*' and next == '/' {
                location.byte_index += int(next_len)
                location.column += 1
                level -= 1

                if level == 0 {
                    break
                }
            } else if curr == '\n' {
                location.line += 1
                location.column = 1
            }

            location.byte_index += int(curr_len)
            location.column += 1
        }
    }

    parse_single_line_comment :: (ref Self) {
        while location.byte_index < text.bytes.length {
            next, len := peek_char(0)
            if next == '`n' {
                break
            }

            location.byte_index += int(len)
            location.column += 1
        }
    }

    check_keywords :: (ref Self, token: ref Token) {
        match token.data {
            TokenData.String($str) -> {
                token.typ =
                    if string.same(str, KwLambda)          then TokenType.KwLambda
                    else if string.same(str, KwReturn)     then TokenType.KwReturn
                    else if string.same(str, KwRef)        then TokenType.KwRef
                    else if string.same(str, Kwfn)         then TokenType.Kwfn
                    else if string.same(str, KwFn)         then TokenType.KwFn
                    else if string.same(str, KwStruct)     then TokenType.KwStruct
                    else if string.same(str, KwEnum)       then TokenType.KwEnum
                    else if string.same(str, KwImpl)       then TokenType.KwImpl
                    else if string.same(str, KwIf)         then TokenType.KwIf
                    else if string.same(str, KwElse)       then TokenType.KwElse
                    else if string.same(str, KwFor)        then TokenType.KwFor
                    else if string.same(str, KwWhile)      then TokenType.KwWhile
                    else if string.same(str, KwLoop)       then TokenType.KwLoop
                    else if string.same(str, KwAnd)        then TokenType.KwAnd
                    else if string.same(str, KwOr)         then TokenType.KwOr
                    else if string.same(str, KwTrue)       then TokenType.KwTrue
                    else if string.same(str, KwFalse)      then TokenType.KwFalse
                    else if string.same(str, KwNull)       then TokenType.KwNull
                    else if string.same(str, KwUsing)      then TokenType.KwUsing
                    else if string.same(str, KwDefer)      then TokenType.KwDefer
                    else if string.same(str, KwMatch)      then TokenType.KwMatch
                    else if string.same(str, KwBreak)      then TokenType.KwBreak
                    else if string.same(str, KwContinue)   then TokenType.KwContinue
                    else if string.same(str, KwTrait)      then TokenType.KwTrait
                    else if string.same(str, KwCast)       then TokenType.KwCast
                    else if string.same(str, KwConst)      then TokenType.KwConst
                    else if string.same(str, KwDefault)    then TokenType.KwDefault
                    else if string.same(str, KwPub)        then TokenType.KwPub
                    else if string.same(str, KwThen)       then TokenType.KwThen
                    else if string.same(str, KwDo)         then TokenType.KwDo
                    else if string.same(str, KwMut)        then TokenType.KwMut
                    else if string.same(str, KwImport)     then TokenType.KwImport
                    else token.typ
            }
        }
    }
}

// token
Location :: struct #copy {
    file        : string = default
    byte_index  : int    = default
    byte_length : int    = default
    line        : int    = default
    column      : int    = default
    end_line    : int    = default
}

impl Location {
    to :: (Self, end: Location) -> Location {
        return Location(
            file        = file
            byte_index  = byte_index
            byte_length = byte_length
            line        = line
            column      = column
            end_line    = end.end_line
        )
    }
}

Token :: struct #copy {
    typ   : TokenType
    location: Location
    suffix  : Option[string]
    data    : TokenData
}

TokenData :: enum #copy {
    None
    String  : string
    Integer : int
    Double  : double
}

impl Printable for Location {
    print :: (ref Self, str: ref String, format: string) {
        str.appendf("{}:{}->{}", (line, column, end_line))
    }
}

impl Printable for Token {
    print :: (ref Self, str: ref String, format: string) {
        str.appendf("{} ({})", (typ, location))
        match data {
            TokenData.String($s) -> str.appendf(" String({})", s)
            TokenData.Integer($s) -> str.appendf(" Int({})", s)
            TokenData.Double($s) -> str.appendf(" Double({})", s)
        }

        match suffix {
            Some($s) -> str.appendf(" Suffix(`"{}`")", (s))
        }
    }
}

impl Printable for TokenType {
    print :: (ref Self, str: ref String, format: string) {
        use TokenType

        str += cast(string)match self {
            Error             -> "Error"
            Unknown           -> "Unknown"
            NewLine           -> "NewLine"
            EOF               -> "EOF"
            StringLiteral     -> "StringLiteral"
            CharLiteral       -> "CharLiteral"
            NumberLiteral     -> "NumberLiteral"
            Identifier        -> "Identifier"
            DollarIdentifier  -> "DollarIdentifier"
            HashIdentifier    -> "HashIdentifier"
            AtSignIdentifier  -> "AtSignIdentifier"
            ReplaceIdentifier -> "ReplaceIdentifier"
            Semicolon         -> "Semicolon"
            Colon             -> "Colon"
            Comma             -> "Comma"
            Period            -> "Period"
            PeriodPeriod      -> "PeriodPeriod"
            Equal             -> "Equal"
            Ampersand         -> "Ampersand"
            Bang              -> "Bang"
            Caret             -> "Caret"
            Plus              -> "Plus"
            Minus             -> "Minus"
            Asterisk          -> "Asterisk"
            ForwardSlash      -> "ForwardSlash"
            Percent           -> "Percent"
            AddEq             -> "AddEq"
            SubEq             -> "SubEq"
            MulEq             -> "MulEq"
            DivEq             -> "DivEq"
            ModEq             -> "ModEq"
            Less              -> "Less"
            LessEqual         -> "LessEqual"
            Greater           -> "Greater"
            GreaterEqual      -> "GreaterEqual"
            DoubleEqual       -> "DoubleEqual"
            NotEqual          -> "NotEqual"
            ReverseArrow      -> "ReverseArrow"
            Arrow             -> "Arrow"
            DoubleArrow       -> "DoubleArrow"
            LessLess          -> "LessLess"
            OpenParen         -> "OpenParen"
            ClosingParen      -> "ClosingParen"
            OpenBrace         -> "OpenBrace"
            ClosingBrace      -> "ClosingBrace"
            OpenBracket       -> "OpenBracket"
            ClosingBracket    -> "ClosingBracket"
            Pipe              -> "Pipe"
            KwLambda          -> "KwLambda"
            KwReturn          -> "KwReturn"
            KwRef             -> "KwRef"
            Kwfn              -> "Kwfn"
            KwFn              -> "KwFn"
            KwStruct          -> "KwStruct"
            KwEnum            -> "KwEnum"
            KwImpl            -> "KwImpl"
            KwIf              -> "KwIf"
            KwElse            -> "KwElse"
            KwFor             -> "KwFor"
            KwWhile           -> "KwWhile"
            KwLoop            -> "KwLoop"
            KwAnd             -> "KwAnd"
            KwOr              -> "KwOr"
            KwTrue            -> "KwTrue"
            KwFalse           -> "KwFalse"
            KwNull            -> "KwNull"
            KwUsing           -> "KwUsing"
            KwDefer           -> "KwDefer"
            KwMatch           -> "KwMatch"
            KwBreak           -> "KwBreak"
            KwContinue        -> "KwContinue"
            KwTrait           -> "KwTrait"
            KwCast            -> "KwCast"
            KwConst           -> "KwConst"
            KwDefault         -> "KwDefault"
            KwPub             -> "KwPub"
            KwThen            -> "KwThen"
            KwDo              -> "KwDo"
            KwMut             -> "KwMut"
            KwImport          -> "KwImport"
        }
    }
}

TokenType :: enum #copy {
    Error
    Unknown
    NewLine
    EOF
    StringLiteral
    CharLiteral
    NumberLiteral
    Identifier
    DollarIdentifier
    HashIdentifier
    AtSignIdentifier
    ReplaceIdentifier
    Semicolon
    Colon
    Comma
    Period
    PeriodPeriod
    Equal
    Ampersand
    Bang
    Caret
    Plus
    Minus
    Asterisk
    ForwardSlash
    Percent
    AddEq
    SubEq
    MulEq
    DivEq
    ModEq
    Less
    LessEqual
    Greater
    GreaterEqual
    DoubleEqual
    NotEqual
    ReverseArrow
    Arrow
    DoubleArrow
    LessLess
    OpenParen
    ClosingParen
    OpenBrace
    ClosingBrace
    OpenBracket
    ClosingBracket
    Pipe
    KwLambda
    KwReturn
    KwRef
    Kwfn
    KwFn
    KwStruct
    KwEnum
    KwImpl
    KwIf
    KwElse
    KwFor
    KwWhile
    KwLoop
    KwAnd
    KwOr
    KwTrue
    KwFalse
    KwNull
    KwUsing
    KwDefer
    KwMatch
    KwBreak
    KwContinue
    KwTrait
    KwCast
    KwConst
    KwDefault
    KwPub
    KwThen
    KwDo
    KwMut
    KwImport
}

#file_scope
is_ident_begin :: (c: char) -> bool {
    return (c >= 'a' and c <= 'z') or (c >= 'A' and c <= 'Z') or (c == '_') or u32(c) > 127
}

is_ident_char :: (c: char) -> bool {
    return is_ident_begin(c) or (c >= '0' and c <= '9')
}

is_digit :: (c: char) -> bool {
    return c >= '0' and c <= '9'
}

is_hex_digit :: (c: char) -> bool {
    return (c >= '0' and c <= '9') or (c >= 'a' and c <= 'f') or (c >= 'A' and c <= 'F')
}

is_binary_digit :: (c: char) -> bool {
    return c >= '0' and c <= '1'
}