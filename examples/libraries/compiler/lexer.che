use import string_database
use import error_handler

use import std.string
use import std.unicode
use import std.printable
use import std.io.fs
use import std.rc

C  :: import std.c
io :: import std.io

#export_scope

Lexer :: struct {
    text        : string
    location    : Location
    peek        : Option[Token]
    offset      : int
    string_db   : &StringDatabase

    // interned keywords
    KwLambda   : string
    KwReturn   : string
    Kwfn       : string
    KwFn       : string
    KwStruct   : string
    KwEnum     : string
    KwImpl     : string
    KwIf       : string
    KwElse     : string
    KwFor      : string
    KwWhile    : string
    KwLoop     : string
    KwAnd      : string
    KwOr       : string
    KwTrue     : string
    KwFalse    : string
    KwNull     : string
    KwUse    : string
    KwDefer    : string
    KwMatch    : string
    KwBreak    : string
    KwContinue : string
    KwTrait    : string
    KwCast     : string
    KwConst    : string
    KwDefault  : string
    KwPub      : string
    KwThen     : string
    KwDo       : string
    KwMut      : string
    KwImport   : string
    KwIn       : string
    KwIs       : string
}

impl TextProvider for Lexer {
    get_text :: (&Self, filename: string) -> string {
        return text
    }
}

impl Lexer {
    // i dont know why, but for some reason when I enable trace-stack this function crashes
    // but with #nostacktrace it works...
    // - NO, 09.12.19
    from_string :: (content: string, string_db: &StringDatabase) -> Rc[Lexer] #nostacktrace {
        return Rc[Lexer].new(Lexer(
            text = content
            location = Location(
                file = "string"
                byte_index  = 0
                byte_length = 1
                line        = 1
                column      = 1
            )
            offset          = 0
            peek            = None
            string_db       = string_db

            KwLambda   = string_db.intern("lambda")
            KwReturn   = string_db.intern("return")
            Kwfn       = string_db.intern("fn")
            KwFn       = string_db.intern("fn")
            KwStruct   = string_db.intern("struct")
            KwEnum     = string_db.intern("enum")
            KwImpl     = string_db.intern("impl")
            KwIf       = string_db.intern("if")
            KwElse     = string_db.intern("else")
            KwFor      = string_db.intern("for")
            KwWhile    = string_db.intern("while")
            KwLoop     = string_db.intern("loop")
            KwAnd      = string_db.intern("and")
            KwOr       = string_db.intern("or")
            KwTrue     = string_db.intern("true")
            KwFalse    = string_db.intern("false")
            KwNull     = string_db.intern("null")
            KwUse      = string_db.intern("use")
            KwDefer    = string_db.intern("defer")
            KwMatch    = string_db.intern("match")
            KwBreak    = string_db.intern("break")
            KwContinue = string_db.intern("continue")
            KwTrait    = string_db.intern("trait")
            KwCast     = string_db.intern("cast")
            KwConst    = string_db.intern("const")
            KwDefault  = string_db.intern("default")
            KwPub      = string_db.intern("pub")
            KwThen     = string_db.intern("then")
            KwDo       = string_db.intern("do")
            KwMut      = string_db.intern("mut")
            KwImport   = string_db.intern("import")
            KwIn       = string_db.intern("in")
            KwIs       = string_db.intern("is")
        ))
    }

    from_file :: (filename: string, string_db: &StringDatabase) -> Result[Rc[Lexer], ()] {
        content := {
            content := try_with(read_file(filename), {return Err(())})
            string_db.intern(content.slice())
        }
        l := Lexer.from_string(content.slice(), string_db)
        l.get().location.file = filename
        return Ok(l)
    }

    current_location :: (&Self) -> Location {
        return match &peek {
            Some($tok) -> tok.location
            None -> location
        }
    }

    expect_token :: (&Self, typ: TokenType) -> bool, Token {
        token := next_token()
        if int(token.typ) == int(typ) {
            return true, token
        } else {
            return false, token
        }
    }

    peek_token :: (&Self) -> &Token {
        return match &peek {
            Some($tok) -> tok

            None -> {
                tok := next_token()
                peek = Some(tok)
                &peek.Some
            }
        }
    }

    next_token :: (&Self) -> Token {
        match peek {
            Some($t) -> {
                peek = None
                return t
            }
        }

        match skip_newlines_and_comments() {
            Some($loc) -> {
                t := Token(
                    typ = TokenType.NewLine
                    location = loc
                    suffix = None
                    data = TokenData.None
                )
                return t
            }
        }

        t := read_token()
        return t
    }

    skip_whitespace :: (&Self) {
        while true {
            tok := self.peek_token()

            match tok.typ {
                TokenType.NewLine -> {
                    self.next_token()
                }

                $_ -> {
                    break
                }
            }
        }
    }

    skip_line :: (&Self) {
        while true {
            tok := self.next_token()

            match tok.typ {
                TokenType.EOF -> {
                    return
                }
                TokenType.NewLine -> {
                    return
                }
            }
        }
    }

    read_token :: (&Self) -> Token {
        token := Token(
            typ      = TokenType.EOF
            data     = TokenData.None
            location = location
            suffix   = None
        )

        token.location.byte_length = 0

        if location.byte_index - offset >= text.bytes.length {
            return token
        }

        curr, curr_len := {
            x := peek_char(0)
            x[0], int(x[1])
        }
        next, next_len := {
            x := peek_char(1)
            x[0], int(x[1])
        }
        next2, next_len2 := {
            x := peek_char(2)
            x[0], int(x[1])
        }

        match curr, next {
            '<', '-' -> simple_token(&token, TokenType.ReverseArrow,   curr_len + next_len, 2)
            '-', '>' -> simple_token(&token, TokenType.Arrow,          curr_len + next_len, 2)
            '=', '>' -> simple_token(&token, TokenType.DoubleArrow,    curr_len + next_len, 2)
            '=', '=' -> simple_token(&token, TokenType.DoubleEqual,    curr_len + next_len, 2)
            '!', '=' -> simple_token(&token, TokenType.NotEqual,       curr_len + next_len, 2)
            '<', '=' -> simple_token(&token, TokenType.LessEqual,      curr_len + next_len, 2)
            '<', '<' -> simple_token(&token, TokenType.LessLess,       curr_len + next_len, 2)
            '>', '=' -> simple_token(&token, TokenType.GreaterEqual,   curr_len + next_len, 2)
            '+', '=' -> simple_token(&token, TokenType.AddEq,          curr_len + next_len, 2)
            '-', '=' -> simple_token(&token, TokenType.SubEq,          curr_len + next_len, 2)
            '*', '=' -> simple_token(&token, TokenType.MulEq,          curr_len + next_len, 2)
            '/', '=' -> simple_token(&token, TokenType.DivEq,          curr_len + next_len, 2)
            '%', '=' -> simple_token(&token, TokenType.ModEq,          curr_len + next_len, 2)
            '.', '.' if next2 == '=' -> simple_token(&token, TokenType.PeriodPeriodEq, curr_len + next_len + next_len2, 3)
            '.', '.' -> simple_token(&token, TokenType.PeriodPeriod,   curr_len + next_len, 2)
            ':', _   -> simple_token(&token, TokenType.Colon,          curr_len, 1)
            ';', _   -> simple_token(&token, TokenType.Semicolon,      curr_len, 1)
            '.', _   -> simple_token(&token, TokenType.Period,         curr_len, 1)
            '=', _   -> simple_token(&token, TokenType.Equal,          curr_len, 1)
            '(', _   -> simple_token(&token, TokenType.OpenParen,      curr_len, 1)
            ')', _   -> simple_token(&token, TokenType.ClosingParen,   curr_len, 1)
            '{', _   -> simple_token(&token, TokenType.OpenBrace,      curr_len, 1)
            '}', _   -> simple_token(&token, TokenType.ClosingBrace,   curr_len, 1)
            '[', _   -> simple_token(&token, TokenType.OpenBracket,    curr_len, 1)
            ']', _   -> simple_token(&token, TokenType.ClosingBracket, curr_len, 1)
            ',', _   -> simple_token(&token, TokenType.Comma,          curr_len, 1)
            '&', _   -> simple_token(&token, TokenType.Ampersand,      curr_len, 1)
            '^', _   -> simple_token(&token, TokenType.Hat,            curr_len, 1)
            '*', _   -> simple_token(&token, TokenType.Asterisk,       curr_len, 1)
            '/', _   -> simple_token(&token, TokenType.ForwardSlash,   curr_len, 1)
            '+', _   -> simple_token(&token, TokenType.Plus,           curr_len, 1)
            '%', _   -> simple_token(&token, TokenType.Percent,        curr_len, 1)
            '-', _   -> simple_token(&token, TokenType.Minus,          curr_len, 1)
            '<', _   -> simple_token(&token, TokenType.Less,           curr_len, 1)
            '>', _   -> simple_token(&token, TokenType.Greater,        curr_len, 1)
            '!', _   -> simple_token(&token, TokenType.Bang,           curr_len, 1)
            '|', _   -> simple_token(&token, TokenType.Pipe,           curr_len, 1)

            '"', _  -> {
                parse_string_literal(&token, TokenType.StringLiteral, '"')
                parse_suffix(&token)
            }
            '`'', _ -> {
                parse_string_literal(&token, TokenType.CharLiteral, '`'')
                parse_suffix(&token)
            }

            // identifiers and keywords
            '$', _ -> {
                location.byte_index += curr_len
                location.column += 1
                parse_identifier(&token, TokenType.DollarIdentifier)
            }
            '#', _ ->  {
                location.byte_index += curr_len
                location.column += 1
                parse_identifier(&token, TokenType.HashIdentifier)
            }
            '@', _ ->  {
                location.byte_index += curr_len
                location.column += 1
                parse_identifier(&token, TokenType.AtSignIdentifier)
            }
            $x, _ if is_ident_begin(x) -> {
                parse_identifier(&token, TokenType.Identifier)
                check_keywords(&token)
            }

            // number literal
            $x, _ if is_digit(x) -> {
                parse_number_literal(&token)
                parse_suffix(&token)
            }

            _, _ -> {
                token.typ = TokenType.Unknown
                location.byte_index += curr_len
            }
        }

        token.location.byte_length = location.byte_index - token.location.byte_index
        token.location.end_column  = location.column
        token.location.end_line    = location.line

        return token
    }

    parse_number_literal :: (&Self, token: &Token) {
        token.typ = TokenType.NumberLiteral
        base := 10
        str := {
            raw := @alloca(u8, 128)
            str := String.from_raw_ptr(raw.data, raw.length)
            str
        }

        is_float := false

        LexerNumberState :: enum #copy {
            Error
            Init
            Done
            Z
            X
            B
            DecDigit
            Dec_
            BinDigit
            Bin_
            HexDigit
            Hex_
            FloatPoint
            FloatDigit
            Float_
        }

        use LexerNumberState

        state := Init
        while location.byte_index - offset < text.bytes.length {
            c, c_len := peek_char(0)
            next, _  := peek_char(1)

            match state {
                Error -> break
                Done  -> break

                Init  -> {
                    if c == '0' {
                        &str += c
                        state = Z
                    } else if is_digit(c) {
                        &str += c
                        state = DecDigit
                    }
                }

                Z -> match c {
                    'x' -> {
                        base = 16
                        str.resize(0)
                        state = X
                    }
                    'b' -> {
                        base = 2
                        str.resize(0)
                        state = B
                    }
                    '.' if next != '.' -> {
                        &str += c
                        state = FloatPoint
                    }
                    $x if is_digit(x) -> {
                        &str += x
                        state = DecDigit
                    }
                    '_' -> {
                        state = Dec_
                    }
                    _ -> {
                        state = Done
                    }
                }

                DecDigit -> match c {
                    '.' if next != '.' -> {
                        &str += c
                        state = FloatPoint
                    }
                    '_' -> {
                        state = Dec_
                    }
                    $x if is_digit(x) -> {
                        &str += c
                    }
                    _ -> {
                        state = Done
                    }
                }

                Dec_ -> match c {
                    $x if is_digit(x) -> {
                        &str += c
                        state = DecDigit
                    }
                    _ -> {
                        state = Error
                    }
                }

                FloatPoint -> {
                    is_float = true
                    if is_digit(c) {
                        &str += c
                        state = FloatDigit
                    } else {
                        state = Error
                    }
                }

                FloatDigit -> match c {
                    $c if is_digit(c) -> {
                        &str += c
                    }
                    '_' -> {
                        state = Float_
                    }
                    $_ -> {
                        state = Done
                    }
                }

                Float_ -> match c {
                    $x if is_digit(x) -> {
                        &str += c
                        state = FloatDigit
                    }
                    _ -> {
                        state = Error
                    }
                }

                X -> match c {
                    $c if is_hex_digit(c) -> {
                        &str += c
                        state = HexDigit
                    }
                    $_ -> {
                        state = Error
                    }
                }

                HexDigit -> match c {
                    $c if is_hex_digit(c) -> {
                        &str += c
                    }
                    '_' -> {
                        state = Hex_
                    }
                    $_ -> {
                        state = Done
                    }
                }

                Hex_ -> match c {
                    $x if is_hex_digit(x) -> {
                        &str += c
                        state = HexDigit
                    }
                    _ -> {
                        state = Error
                    }
                }

                B -> match c {
                    $c if is_binary_digit(c) -> {
                        &str += c
                        state = BinDigit
                    }
                    $_ -> {
                        state = Error
                    }
                }

                BinDigit -> match c {
                    $c if is_binary_digit(c) -> {
                        &str += c
                    }
                    '_' -> {
                        state = Bin_
                    }
                    $_ -> {
                        state = Done
                    }
                }

                Bin_ -> match c {
                    $x if is_binary_digit(x) -> {
                        &str += c
                        state = BinDigit
                    }
                    _ -> {
                        state = Error
                    }
                }
            }

            match state {
                Done -> break
                Error -> break
                $_   -> {
                    location.byte_index += int(c_len)
                    location.column += 1
                }
            }
        }

        match state {
            Error -> {
                token.typ = TokenType.Error
                token.data = TokenData.String("Invalid number literal")
                return
            }
        }

        &str += '`0'

        if is_float {
            d := C.strtod(cast str.get_raw(), null)
            token.data = TokenData.Double(d)
        } else {
            i := C.strtol(cast str.get_raw(), null, cast base)
            token.data = TokenData.Integer(i)
        }
    }

    parse_suffix :: (&Self, token: &Token) {
        if is_ident_begin(peek_char(0)[0]) {
            start := location.byte_index - offset
            while location.byte_index - offset < text.bytes.length {
                c, c_len := peek_char(0)
                if !is_ident_char(c) then break
                location.byte_index += int(c_len)
                location.column += 1
            }

            token.suffix = Some(text[start .. location.byte_index - offset])
        }
    }

    simple_token :: (&Self, token: &Token, typ: TokenType, len: int, chars: int) {
        token.typ = typ
        location.byte_index += len
        location.column += chars
    }

    parse_identifier :: (&Self, token: &Token, typ: TokenType) {
        token.typ = typ
        start := location.byte_index - offset

        while location.byte_index - offset < text.bytes.length {
            c, c_len := peek_char(0)
            if !is_ident_char(c) then break
            location.byte_index += int(c_len)
            location.column += 1
        }

        str := text[start .. location.byte_index - offset]
        token.data = TokenData.String(string_db.intern(str))
    }

    parse_string_literal :: (&Self, token: &Token, typ: TokenType, end: char) {
        token.typ = typ
        location.byte_index += 1
        location.column += 1
        start := location.byte_index - offset

        foundEnd := false
        while location.byte_index - offset < text.bytes.length {
            c, c_len := peek_char(0)
            location.byte_index += int(c_len)
            location.column += 1

            if c == end {
                foundEnd = true
                break
            } else if c == '``' {
                if location.byte_index - offset >= text.bytes.length {
                    // TODO: report error
                    break
                }

                location.byte_index += int(c_len)
                location.column += 1
            }

            if c == '`n' {
                location.column = 1
                location.line += 1
            }
        }

        if !foundEnd {
            // TODO: report
        }

        str := text[start .. location.byte_index - offset - 1]
        token.data = TokenData.String(string_db.intern(str))
    }

    skip_newlines_and_comments :: (&Self) -> loc: Option[Location] {
        loc = None

        while location.byte_index - offset < text.bytes.length {
            curr, curr_len := peek_char(0)
            next, next_len := peek_char(1)

            if curr == '/' and next == '*' {
                parse_multi_line_comment()
            } else if curr == '/' and next == '/' {
                parse_single_line_comment()
            } else if curr == ' ' or curr == '`t' {
                location.byte_index += int(curr_len)
                location.column += 1
            } else if curr == '`r' {
                location.byte_index += int(curr_len)
                location.column += 1
            } else if curr == '`n' {
                match loc {
                    None -> {
                        loc = Some(location)
                    }
                }

                location.line += 1
                location.byte_index += int(curr_len)
                location.column = 1
            } else {
                break
            }
        }
    }

    peek_char :: (&Self, offset: int) -> char, i32 {
        index := location.byte_index - self.offset
        while offset > 0, offset -= 1 {
            _, len := Utf8.decode(text.slice().bytes[index..text.bytes.length])
            index += int(len)
        }
        if index >= text.bytes.length {
            return char(0), 0
        }

        return Utf8.decode(text.bytes[index..text.bytes.length])
    }

    parse_multi_line_comment :: (&Self) {
        level := 0
        while location.byte_index - offset < text.bytes.length {
            curr, curr_len := peek_char(0)
            next, next_len := peek_char(1)

            if curr == '/' and next == '*' {
                location.byte_index += int(next_len)
                location.column += 1
                level += 1
            } else if curr == '*' and next == '/' {
                location.byte_index += int(next_len)
                location.column += 1
                level -= 1

                if level == 0 {
                    break
                }
            } else if curr == '\n' {
                location.line += 1
                location.column = 1
            }

            location.byte_index += int(curr_len)
            location.column += 1
        }
    }

    parse_single_line_comment :: (&Self) {
        while location.byte_index - offset < text.bytes.length {
            next, len := peek_char(0)
            if next == '`n' {
                break
            }

            location.byte_index += int(len)
            location.column += 1
        }
    }

    check_keywords :: (&Self, token: &Token) {
        match token.data {
            TokenData.String($str) -> {
                token.typ =
                    if string.same(str, KwLambda)          then TokenType.KwLambda
                    else if string.same(str, KwReturn)     then TokenType.KwReturn
                    else if string.same(str, Kwfn)         then TokenType.Kwfn
                    else if string.same(str, KwFn)         then TokenType.KwFn
                    else if string.same(str, KwStruct)     then TokenType.KwStruct
                    else if string.same(str, KwEnum)       then TokenType.KwEnum
                    else if string.same(str, KwImpl)       then TokenType.KwImpl
                    else if string.same(str, KwIf)         then TokenType.KwIf
                    else if string.same(str, KwElse)       then TokenType.KwElse
                    else if string.same(str, KwFor)        then TokenType.KwFor
                    else if string.same(str, KwWhile)      then TokenType.KwWhile
                    else if string.same(str, KwLoop)       then TokenType.KwLoop
                    else if string.same(str, KwAnd)        then TokenType.KwAnd
                    else if string.same(str, KwOr)         then TokenType.KwOr
                    else if string.same(str, KwTrue)       then TokenType.KwTrue
                    else if string.same(str, KwFalse)      then TokenType.KwFalse
                    else if string.same(str, KwNull)       then TokenType.KwNull
                    else if string.same(str, KwUse)        then TokenType.KwUse
                    else if string.same(str, KwDefer)      then TokenType.KwDefer
                    else if string.same(str, KwMatch)      then TokenType.KwMatch
                    else if string.same(str, KwBreak)      then TokenType.KwBreak
                    else if string.same(str, KwContinue)   then TokenType.KwContinue
                    else if string.same(str, KwTrait)      then TokenType.KwTrait
                    else if string.same(str, KwCast)       then TokenType.KwCast
                    else if string.same(str, KwConst)      then TokenType.KwConst
                    else if string.same(str, KwDefault)    then TokenType.KwDefault
                    else if string.same(str, KwPub)        then TokenType.KwPub
                    else if string.same(str, KwThen)       then TokenType.KwThen
                    else if string.same(str, KwDo)         then TokenType.KwDo
                    else if string.same(str, KwMut)        then TokenType.KwMut
                    else if string.same(str, KwImport)     then TokenType.KwImport
                    else if string.same(str, KwIn)         then TokenType.KwIn
                    else if string.same(str, KwIs)         then TokenType.KwIs
                    else token.typ
            }
        }
    }
}

// token
Location :: struct #copy {
    file        : string = default
    byte_index  : int    = default
    byte_length : int    = default
    line        : int    = default
    column      : int    = default
    end_column  : int    = default
    end_line    : int    = default
}

impl Location {
    to :: (Self, end: Location) -> Location {
        return Location(
            file        = file
            byte_index  = byte_index
            byte_length = end.byte_index + end.byte_length - byte_index
            line        = line
            column      = column
            end_column  = end.end_column
            end_line    = end.end_line
        )
    }

    end :: (Self) -> Location {
        return Location(
            file        = file
            byte_index  = byte_index + byte_length
            byte_length = 0
            line        = end_line
            column      = end_column
            end_column  = end_column
            end_line    = end_line
        )
    }
}

Token :: struct #copy {
    typ         : TokenType
    location    : Location
    suffix      : Option[string]
    data        : TokenData
}

TokenData :: enum #copy {
    None
    String  : string
    Integer : int
    Double  : double
}

impl Printable for Location {
    print :: (&Self, str: &String, format: string) {
        str.appendf("{}:{}:{}", (file, line, column, end_line))
    }
}

impl Printable for Token {
    print :: (&Self, str: &String, format: string) {
        str.appendf("{} ({})", (typ, location))
        match data {
            TokenData.String($s) -> str.appendf(" String({})", s)
            TokenData.Integer($s) -> str.appendf(" Int({})", s)
            TokenData.Double($s) -> str.appendf(" Double({})", s)
        }

        match suffix {
            Some($s) -> str.appendf(" Suffix(`"{}`")", (s))
        }
    }
}

impl Printable for TokenType {
    print :: (&Self, str: &String, format: string) {
        use TokenType

        str += cast(string)match self {
            Error             -> "Error"
            Unknown           -> "Unknown"
            NewLine           -> "NewLine"
            EOF               -> "EOF"
            StringLiteral     -> "StringLiteral"
            CharLiteral       -> "CharLiteral"
            NumberLiteral     -> "NumberLiteral"
            Identifier        -> "Identifier"
            DollarIdentifier  -> "DollarIdentifier"
            HashIdentifier    -> "HashIdentifier"
            AtSignIdentifier  -> "AtSignIdentifier"
            ReplaceIdentifier -> "ReplaceIdentifier"
            Semicolon         -> "Semicolon"
            Colon             -> "Colon"
            Comma             -> "Comma"
            Period            -> "Period"
            PeriodPeriod      -> "PeriodPeriod"
            PeriodPeriodEq    -> "PeriodPeriodEq"
            Equal             -> "Equal"
            Ampersand         -> "Ampersand"
            Hat               -> "Hat"
            Bang              -> "Bang"
            Plus              -> "Plus"
            Minus             -> "Minus"
            Asterisk          -> "Asterisk"
            ForwardSlash      -> "ForwardSlash"
            Percent           -> "Percent"
            AddEq             -> "AddEq"
            SubEq             -> "SubEq"
            MulEq             -> "MulEq"
            DivEq             -> "DivEq"
            ModEq             -> "ModEq"
            Less              -> "Less"
            LessEqual         -> "LessEqual"
            Greater           -> "Greater"
            GreaterEqual      -> "GreaterEqual"
            DoubleEqual       -> "DoubleEqual"
            NotEqual          -> "NotEqual"
            ReverseArrow      -> "ReverseArrow"
            Arrow             -> "Arrow"
            DoubleArrow       -> "DoubleArrow"
            LessLess          -> "LessLess"
            OpenParen         -> "OpenParen"
            ClosingParen      -> "ClosingParen"
            OpenBrace         -> "OpenBrace"
            ClosingBrace      -> "ClosingBrace"
            OpenBracket       -> "OpenBracket"
            ClosingBracket    -> "ClosingBracket"
            Pipe              -> "Pipe"
            KwLambda          -> "KwLambda"
            KwReturn          -> "KwReturn"
            Kwfn              -> "Kwfn"
            KwFn              -> "KwFn"
            KwStruct          -> "KwStruct"
            KwEnum            -> "KwEnum"
            KwImpl            -> "KwImpl"
            KwIf              -> "KwIf"
            KwElse            -> "KwElse"
            KwFor             -> "KwFor"
            KwWhile           -> "KwWhile"
            KwLoop            -> "KwLoop"
            KwAnd             -> "KwAnd"
            KwOr              -> "KwOr"
            KwTrue            -> "KwTrue"
            KwFalse           -> "KwFalse"
            KwNull            -> "KwNull"
            KwUse             -> "KwUse"
            KwDefer           -> "KwDefer"
            KwMatch           -> "KwMatch"
            KwBreak           -> "KwBreak"
            KwContinue        -> "KwContinue"
            KwTrait           -> "KwTrait"
            KwCast            -> "KwCast"
            KwConst           -> "KwConst"
            KwDefault         -> "KwDefault"
            KwPub             -> "KwPub"
            KwThen            -> "KwThen"
            KwDo              -> "KwDo"
            KwMut             -> "KwMut"
            KwImport          -> "KwImport"
            KwIn              -> "KwIn"
            KwIs              -> "KwIs"
        }
    }
}

TokenType :: enum #copy {
    Error
    Unknown
    NewLine
    EOF
    StringLiteral
    CharLiteral
    NumberLiteral
    Identifier
    DollarIdentifier
    HashIdentifier
    AtSignIdentifier
    ReplaceIdentifier
    Semicolon
    Colon
    Comma
    Period
    PeriodPeriod
    PeriodPeriodEq
    Equal
    Ampersand
    Hat
    Bang
    Plus
    Minus
    Asterisk
    ForwardSlash
    Percent
    AddEq
    SubEq
    MulEq
    DivEq
    ModEq
    Less
    LessEqual
    Greater
    GreaterEqual
    DoubleEqual
    NotEqual
    ReverseArrow
    Arrow
    DoubleArrow
    LessLess
    OpenParen
    ClosingParen
    OpenBrace
    ClosingBrace
    OpenBracket
    ClosingBracket
    Pipe
    KwLambda
    KwReturn
    Kwfn
    KwFn
    KwStruct
    KwEnum
    KwImpl
    KwIf
    KwElse
    KwFor
    KwWhile
    KwLoop
    KwAnd
    KwOr
    KwTrue
    KwFalse
    KwNull
    KwUse
    KwDefer
    KwMatch
    KwBreak
    KwContinue
    KwTrait
    KwCast
    KwConst
    KwDefault
    KwPub
    KwThen
    KwDo
    KwMut
    KwImport
    KwIn
    KwIs
}

#file_scope
is_ident_begin :: (c: char) -> bool {
    return (c >= 'a' and c <= 'z') or (c >= 'A' and c <= 'Z') or (c == '_') or u32(c) > 127
}

is_ident_char :: (c: char) -> bool {
    return is_ident_begin(c) or (c >= '0' and c <= '9')
}

is_digit :: (c: char) -> bool {
    return c >= '0' and c <= '9'
}

is_hex_digit :: (c: char) -> bool {
    return (c >= '0' and c <= '9') or (c >= 'a' and c <= 'f') or (c >= 'A' and c <= 'F')
}

is_binary_digit :: (c: char) -> bool {
    return c >= '0' and c <= '1'
}