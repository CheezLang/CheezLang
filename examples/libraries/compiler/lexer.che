use import string_database

use import std.string
use import std.unicode
use import std.printable
use import std.io.file
C :: import std.c
io :: import std.io

#export_scope

Lexer :: struct {
    text        : String
    location    : TokenLocation
    peek        : Option[Token]
    string_db   : ref StringDatabase

    
    // interned keywords
    KwReturn    : string
    KwNew       : string
    KwRef       : string
    KwFn        : string
    KwStruct    : string
    KwEnum      : string
    KwImpl      : string
    KwConst     : string
    KwLet       : string
    KwTypedef   : string
    KwIf        : string
    KwElse      : string
    KwFor       : string
    KwWhile     : string
    KwAnd       : string
    KwOr        : string
    KwTrue      : string
    KwFalse     : string
    KwNull      : string
    KwUsing     : string
    KwDefer     : string
    KwMatch     : string
    KwBreak     : string
    KwContinue  : string
    KwTrait     : string
    KwCast      : string
}

is_ident_begin :: (c: char) -> bool {
    return (c >= 'a' and c <= 'z') or (c >= 'A' and c <= 'Z') or (c == '_')
}

is_ident_char :: (c: char) -> bool {
    return is_ident_begin(c) or (c >= '0' and c <= '9')
}

is_digit :: (c: char) -> bool {
    return c >= '0' and c <= '9'
}

is_hex_digit :: (c: char) -> bool {
    return (c >= '0' and c <= '9') or (c >= 'a' and c <= 'f') or (c >= 'A' and c <= 'F')
}

is_binary_digit :: (c: char) -> bool {
    return c >= '0' and c <= '1'
}

LexerNumberState :: enum {
    Error
    Init
    Z
    X
    B
    DecDigit
    BinDigit
    HexDigit
    Done
    FloatPoint
    FloatDigit
}

impl Lexer {
    from_raw_string :: (content: string, string_db: ref StringDatabase) -> Lexer {
        return from_string(String.from_string(content), string_db)
    }

    from_string :: (content: String, string_db: ref StringDatabase) -> Lexer {
        return Lexer(
            text = content
            location = TokenLocation(
                file = "string"
                line = 1
                index = 0
                end = 0
                line_start = 0
            )
            peek = None
            string_db = string_db

            KwReturn    = string_db.intern("return")
            KwNew       = string_db.intern("new")
            KwRef       = string_db.intern("ref")
            KwFn        = string_db.intern("fn")
            KwStruct    = string_db.intern("struct")
            KwEnum      = string_db.intern("enum")
            KwImpl      = string_db.intern("impl")
            KwConst     = string_db.intern("const")
            KwLet       = string_db.intern("let")
            KwTypedef   = string_db.intern("typedef")
            KwIf        = string_db.intern("if")
            KwElse      = string_db.intern("else")
            KwFor       = string_db.intern("for")
            KwWhile     = string_db.intern("while")
            KwAnd       = string_db.intern("and")
            KwOr        = string_db.intern("or")
            KwTrue      = string_db.intern("true")
            KwFalse     = string_db.intern("false")
            KwNull      = string_db.intern("null")
            KwUsing     = string_db.intern("using")
            KwDefer     = string_db.intern("defer")
            KwMatch     = string_db.intern("match")
            KwBreak     = string_db.intern("break")
            KwContinue  = string_db.intern("continue")
            KwTrait     = string_db.intern("trait")
            KwCast      = string_db.intern("cast")
        )
    }

    from_file :: (filename: string, string_db: ref StringDatabase) -> Result[Lexer, String] {
        return match load_file(filename) {
            Ok($content) -> {
                l := Lexer.from_string(content, string_db)
                l.location.file = filename
                Ok(l)
            }
            Err($msg) -> Err(msg)
        }
    }

    peek_token :: (ref Self) -> Token {
        return match peek {
            Some($tok) -> tok

            None -> {
                tok := next_token()
                peek = Some(tok)
                tok
            }
        }
    }

    next_token :: (ref Self) -> Token {
        match peek {
            Some($t) -> {
                peek = None
                return t
            }
        }

        match skip_newlines_and_comments() {
            Some($loc) -> {
                loc.end = loc.index
                return Token(
                    ttype = TokenType.NewLine
                    location = loc
                    suffix = None
                    data = TokenData.None
                )
            }
        }

        return read_token()
    }

    read_token :: (ref Self) -> Token {
        token := Token(
            ttype = TokenType.EOF
            data = TokenData.None
            location = location
            suffix = None
        )
        token.location.end = token.location.index

        if location.index >= text.length {
            return token
        }

        curr := peek_char(0)
        next := peek_char(1)

        match curr {
            '=' if next == '=' -> simple_token(token, TokenType.DoubleEqual, 2)
            '!' if next == '=' -> simple_token(token, TokenType.NotEqual, 2)
            '<' if next == '=' -> simple_token(token, TokenType.LessEqual, 2)
            '<' if next == '<' -> simple_token(token, TokenType.LessLess, 2)
            '>' if next == '=' -> simple_token(token, TokenType.GreaterEqual, 2)
            ':' if next == ':' -> simple_token(token, TokenType.DoubleColon, 2)
            '-' if next == '>' -> simple_token(token, TokenType.Arrow, 2)
            '+' if next == '=' -> simple_token(token, TokenType.AddEq, 2)
            '-' if next == '=' -> simple_token(token, TokenType.SubEq, 2)
            '*' if next == '=' -> simple_token(token, TokenType.MulEq, 2)
            '/' if next == '=' -> simple_token(token, TokenType.DivEq, 2)
            '%' if next == '=' -> simple_token(token, TokenType.ModEq, 2)
            ':' -> simple_token(token, TokenType.Colon)
            ';' -> simple_token(token, TokenType.Semicolon)
            '.' -> simple_token(token, TokenType.Period)
            '=' -> simple_token(token, TokenType.Equal)
            '(' -> simple_token(token, TokenType.OpenParen)
            ')' -> simple_token(token, TokenType.ClosingParen)
            '{' -> simple_token(token, TokenType.OpenBrace)
            '}' -> simple_token(token, TokenType.ClosingBrace)
            '[' -> simple_token(token, TokenType.OpenBracket)
            ']' -> simple_token(token, TokenType.ClosingBracket)
            ',' -> simple_token(token, TokenType.Comma)
            '&' -> simple_token(token, TokenType.Ampersand)
            '*' -> simple_token(token, TokenType.Asterisk)
            '/' -> simple_token(token, TokenType.ForwardSlash)
            '+' -> simple_token(token, TokenType.Plus)
            '%' -> simple_token(token, TokenType.Percent)
            '-' -> simple_token(token, TokenType.Minus)
            '<' -> simple_token(token, TokenType.Less)
            '>' -> simple_token(token, TokenType.Greater)
            '!' -> simple_token(token, TokenType.Bang)
            '^' -> simple_token(token, TokenType.Caret)

            '"' -> {
                parse_string_literal(token, TokenType.StringLiteral, '"')
                parse_suffix(token)
            }
            '`'' -> {
                parse_string_literal(token, TokenType.CharLiteral, '`'')
                parse_suffix(token)
            }

            // identifiers and keywords
            '$' -> {
                location.index += 1
                parse_identifier(token, TokenType.DollarIdentifier)
            }
            '#' ->  {
                location.index += 1
                parse_identifier(token, TokenType.HashIdentifier)
            }
            '@' ->  {
                location.index += 1
                parse_identifier(token, TokenType.AtSignIdentifier)
            }
            $x if is_ident_begin(x) -> {
                parse_identifier(token, TokenType.Identifier)
                check_keywords(token)
                // check_keywords_raw(token)
            }

            // number literal
            $x if is_digit(x) -> {
                parse_number_literal(token)
                parse_suffix(token)
            }

            $_ -> {
                token.ttype = TokenType.Unknown
                location.index += 1
            }
        }

        token.location.end = location.index

        return token
    }

    parse_number_literal :: (ref Self, token: ref Token) {
        token.ttype = TokenType.NumberLiteral
        base := 10
        str := {
            cap :: 64
            raw := @alloca(u8, cap)
            str := String.from_raw_ptr(raw, cap)
            str
        }

        isFloat := false

        use LexerNumberState

        state := Init
        while location.index < text.length {
            c := peek_char(0)
            match state {
                Error -> {break}
                Done  -> {break}

                Init  -> {
                    if c == '0' {
                        str += c
                        state = Z
                    } else if is_digit(c) {
                        str += c
                        state = DecDigit
                    }
                }

                Z -> match c {
                    'x' -> {
                        base = 16
                        str.resize(0)
                        state = X
                    }
                    'b' -> {
                        base = 2
                        str.resize(0)
                        state = B
                    }
                    '.' -> {
                        str += c
                        state = FloatPoint
                    }
                    $x if is_digit(x) -> {
                        str += x
                        state = DecDigit
                    }
                    $_ -> {
                        state = Done
                    }
                }

                DecDigit -> match c {
                    '.' -> {
                        str += c
                        state = FloatPoint
                    }
                    $x if is_digit(x) -> {
                        str += c
                    }
                    $_ -> {
                        state = Done
                    }
                }

                FloatPoint -> {
                    isFloat = true
                    if is_digit(c) {
                        str += c
                        state = FloatDigit
                    } else {
                        state = Error
                    }
                }

                FloatDigit -> match c {
                    $c if is_digit(c) -> {
                        str += c
                    }
                    $_ -> {
                        state = Done
                    }
                }

                X -> match c {
                    $c if is_hex_digit(c) -> {
                        str += c
                        state = HexDigit
                    }
                    $_ -> {
                        state = Error
                    }
                }

                HexDigit -> match c {
                    $c if is_hex_digit(c) -> {
                        str += c
                    }
                    $_ -> {
                        state = Done
                    }
                }

                B -> match c {
                    $c if is_binary_digit(c) -> {
                        str += c
                        state = BinDigit
                    }
                    $_ -> {
                        state = Error
                    }
                }

                BinDigit -> match c {
                    $c if is_binary_digit(c) -> {
                        str += c
                    }
                    $_ -> {
                        state = Done
                    }
                }
            }

            match state {
                Done -> {}
                $_   -> {
                    location.index += 1
                }
            }
        }

        match state {
            Error -> {
                // TODO: report error
                token.ttype = TokenType.Unknown
                return
            }
        }

        str += '`0'

        if isFloat {
            d := C.strtod(cast str.get_raw(), null)
            token.data = TokenData.Double(d)
        } else {
            i := C.strtol(cast str.get_raw(), null, cast base)
            token.data = TokenData.Integer(i)
        }
    }

    parse_suffix :: (ref Self, token: ref Token) {
        if is_ident_begin(peek_char(0)) {
            start := location.index
            while location.index < text.length and is_ident_char(peek_char(0)) {
                location.index += 1
            }

            token.suffix = Some(text.sliceFL(start, location.index - start))
        }
    }

    simple_token :: (ref Self, token: ref Token, ttype: TokenType, len: int = 1) {
        token.ttype = ttype
        location.index += len
    }

    parse_identifier :: (ref Self, token: ref Token, ttype: TokenType) {
        token.ttype = ttype
        start := location.index

        while location.index < text.length and is_ident_char(peek_char(0)) {
            location.index += 1
        }

        str := text.sliceFL(start, location.index - start)
        token.data = TokenData.String(string_db.intern(str))
    }

    parse_string_literal :: (ref Self, token: ref Token, ttype: TokenType, end: char) {
        token.ttype = ttype
        location.index += 1
        start := location.index

        foundEnd := false
        while location.index < text.length {
            c := peek_char(0)
            location.index += 1

            if c == end {
                foundEnd = true
                break
            } else if c == '``' {
                if location.index >= text.length {
                    // TODO: report error
                    break
                }

                location.index += 1
            }

            if c == '`n' {
                location.line += 1
                location.line_start = location.index
            }
        }

        if !foundEnd {
            // TODO: report
        }

        str := text.sliceFL(start, location.index - start - 1)
        token.data = TokenData.String(string_db.intern(str))
    }

    skip_newlines_and_comments :: (ref Self) -> loc: Option[TokenLocation] {
        loc = None

        while location.index < text.length {
            c := peek_char(0)
            next := peek_char(1)

            if c == '/' and next == '*' {
                parse_multi_line_comment()
            } else if c == '/' and next == '/' {
                parse_single_line_comment()
            } else if c == ' ' or c == '`t' {
                location.index += 1
            } else if c == '`r' {
                location.index += 1
            } else if c == '`n' {
                match loc {
                    None -> {
                        loc = Some(location)
                    }
                }

                location.line += 1
                location.index += 1
                location.line_start = location.index
            } else {
                break
            }
        }
    }

    peek_char :: (ref Self, offset: int) -> char {
        index := location.index + offset
        if index >= text.length {
            return '`0'
        }

        code_point, _ := Utf8.decode(text.slice().bytes[index..text.length])
        return code_point
    }

    parse_multi_line_comment :: (ref Self) {
        level := 0
        while location.index < text.length, location.index += 1 {
            curr := peek_char(0)
            next := peek_char(1)

            if curr == '/' and next == '*' {
                location.index += 1
                level += 1
            } else if curr == '*' and next == '/' {
                location.index += 1
                level -= 1

                if level == 0 {
                    break
                }
            } else if curr == '\n' {
                location.line += 1
                location.line_start = location.index
            }
        }
    }

    parse_single_line_comment :: (ref Self) {
        while location.index < text.length {
            if peek_char(0) == '`n' {
                break
            }

            location.index += 1
        }
    }

    check_keywords :: (ref Self, token: ref Token) {
        match token.data {
            TokenData.String($str) -> {
                token.ttype =
                    if      str == KwReturn     then TokenType.KwReturn
                    else if str == KwNew        then TokenType.KwNew
                    else if str == KwRef        then TokenType.KwRef
                    else if str == KwFn         then TokenType.KwFn
                    else if str == KwStruct     then TokenType.KwStruct
                    else if str == KwEnum       then TokenType.KwEnum
                    else if str == KwImpl       then TokenType.KwImpl
                    else if str == KwConst      then TokenType.KwConst
                    else if str == KwLet        then TokenType.KwLet
                    else if str == KwTypedef    then TokenType.KwTypedef
                    else if str == KwIf         then TokenType.KwIf
                    else if str == KwElse       then TokenType.KwElse
                    else if str == KwFor        then TokenType.KwFor
                    else if str == KwWhile      then TokenType.KwWhile
                    else if str == KwAnd        then TokenType.KwAnd
                    else if str == KwOr         then TokenType.KwOr
                    else if str == KwTrue       then TokenType.KwTrue
                    else if str == KwFalse      then TokenType.KwFalse
                    else if str == KwNull       then TokenType.KwNull
                    else if str == KwUsing      then TokenType.KwUsing
                    else if str == KwDefer      then TokenType.KwDefer
                    else if str == KwMatch      then TokenType.KwMatch
                    else if str == KwBreak      then TokenType.KwBreak
                    else if str == KwContinue   then TokenType.KwContinue
                    else if str == KwTrait      then TokenType.KwTrait
                    else if str == KwCast       then TokenType.KwCast
                    else                             token.ttype
            }
        }
    }
}

// token
Location :: (beg: TokenLocation, end: TokenLocation)

TokenLocation :: struct #copy {
    file            : string
    line            : int
    index           : int
    end             : int
    line_start      : int
}

Token :: struct #copy {
    ttype   : TokenType
    location: TokenLocation
    suffix  : Option[string]
    data    : TokenData
}

TokenData :: enum #copy {
    None
    String  : string
    Integer : int
    Double  : double
}

impl Printable for TokenLocation {
    print :: (ref Self, str: ref String, format: string) {
        column := index - line_start
        str.appendf("{}:{}:{}", (file, line, column))
    }
}

impl Printable for Token {
    print :: (ref Self, str: ref String, format: string) {
        str.appendf("{} ({})", (ttype, location))
        match data {
            TokenData.String($s) -> str.appendf(" String({})", s)
            TokenData.Integer($s) -> str.appendf(" Int({})", s)
            TokenData.Double($s) -> str.appendf(" Double({})", s)
        }

        match suffix {
            Some($s) -> str.appendf(" Suffix(`"{}`")", (s))
        }
    }
}

impl Printable for TokenType {
    print :: (ref Self, str: ref String, format: string) {
        use TokenType

        str += cast(string)match self {
            Unknown         -> "Unknown"
            NewLine         -> "NewLine"
            EOF             -> "EOF"
            StringLiteral   -> "StringLiteral"
            CharLiteral     -> "CharLiteral"
            NumberLiteral   -> "NumberLiteral"
            Identifier      -> "Identifier"
            DollarIdentifier-> "DollarIdentifier"
            HashIdentifier  -> "HashIdentifier"
            AtSignIdentifier-> "AtSignIdentifier"
            Semicolon       -> "Semicolon"
            DoubleColon     -> "DoubleColon"
            Colon           -> "Colon"
            Comma           -> "Comma"
            Period          -> "Period"
            Equal           -> "Equal"
            Ampersand       -> "Ampersand"
            Bang            -> "Bang"
            Plus            -> "Plus"
            Minus           -> "Minus"
            Asterisk        -> "Asterisk"
            ForwardSlash    -> "ForwardSlash"
            Percent         -> "Percent"
            AddEq           -> "AddEq"
            SubEq           -> "SubEq"
            MulEq           -> "MulEq"
            DivEq           -> "DivEq"
            ModEq           -> "ModEq"
            Less            -> "Less"
            LessEqual       -> "LessEqual"
            Greater         -> "Greater"
            Greater         -> "GreaterEqual"
            DoubleEqual     -> "DoubleEqual"
            NotEqual        -> "NotEqual"
            Arrow           -> "Arrow"
            LessLess        -> "LessLess"
            Caret           -> "Caret"
            OpenParen       -> "OpenParen"
            ClosingParen    -> "ClosingParen"
            OpenBrace       -> "OpenBrace"
            ClosingBrace    -> "ClosingBrace"
            OpenBracket     -> "OpenBracket"
            ClosingBracket  -> "ClosingBracket"
            KwReturn        -> "KwReturn"
            KwNew           -> "KwNew"
            KwRef           -> "KwRef"
            KwFn            -> "KwFn"
            KwStruct        -> "KwStruct"
            KwEnum          -> "KwEnum"
            KwImpl          -> "KwImpl"
            KwConst         -> "const"
            KwLet           -> "KwLet"
            KwTypedef       -> "KwTypedef"
            KwIf            -> "KwIf"
            KwElse          -> "KwElse"
            KwFor           -> "KwFor"
            KwWhile         -> "KwWhile"
            KwAnd           -> "KwAnd"
            KwOr            -> "KwOr"
            KwTrue          -> "KwTrue"
            KwFalse         -> "KwFalse"
            KwNull          -> "KwNull"
            KwUsing         -> "KwUsing"
            KwDefer         -> "KwDefer"
            KwMatch         -> "KwMatch"
            KwBreak         -> "KwBreak"
            KwContinue      -> "KwContinue"
            KwTrait         -> "KwTrait"
            KwCast          -> "KwCast"
        }
    }
}

TokenType :: enum #copy {
    Unknown

    NewLine
    EOF

    StringLiteral
    CharLiteral
    NumberLiteral

    Identifier
    DollarIdentifier
    HashIdentifier
    AtSignIdentifier

    Semicolon
    DoubleColon
    Colon
    Comma
    Period
    Equal
    Ampersand

    Bang

    Plus
    Minus
    Asterisk
    ForwardSlash
    Percent

    AddEq
    SubEq
    MulEq
    DivEq
    ModEq

    Less
    LessEqual
    Greater
    GreaterEqual
    DoubleEqual
    NotEqual

    Arrow
    LessLess
    Caret

    OpenParen
    ClosingParen

    OpenBrace
    ClosingBrace

    OpenBracket
    ClosingBracket

    KwReturn
    KwNew
    KwRef
    KwFn
    KwStruct
    KwEnum
    KwImpl
    KwConst
    KwLet
    KwTypedef
    KwIf
    KwElse
    KwFor
    KwWhile
    KwAnd
    KwOr
    KwTrue
    KwFalse
    KwNull
    KwUsing
    KwDefer
    KwMatch
    KwBreak
    KwContinue
    KwTrait
    KwCast
}
